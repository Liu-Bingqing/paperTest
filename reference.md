# Reference
References:
[1]	Ghatak, Subhankar, Rup, et al.GAN based efficient foreground extraction and HGWOSA based optimization for video synopsis generation[J].Digital Signal Processing,2021,111,102988.
[2]	Tan Jia-wai, Ding Qi-chuan, Bai Zhong-yu.Optimal Estimation Method of 3-Dimensional Human Pose Based on Video Frame Coherent Information[J]. Robot,2021,43(01): 9-16.
[2]	谭嘉崴,丁其川,白忠玉.基于视频帧连贯信息的3维人体姿势优化估计方法[J].机器人,2021,43(01):9-16.
[3]	Chen Quan, Huang Jun, Xu Fang. Research on improved visual background extraction algorithm in indoor[J]. Journal of Chinese Computer Systems,2021,42(06):1250-1255.
[3]	陈权,黄俊,徐访.改进视觉背景提取算法在室内的研究[J].小型微型计算机系统,2021,42(06):1250-1255.
[4]	Songwen Pei, Fuwu Tang, Yanfei Ji, et al.Localized Traffic Sign Detection with Multi-scale Deconvolution Networks[C]//2018 42nd IEEE International Conference on Computer Software & Applications (COMPSAC).2018,
122:580-588.
[5]	Sheng Mengxue, Hou Wanwan, Jiang Juchao. Implementation of Accelerating Video Preprocessing based on ZYNQ Platform Resource Management[J].Journal of Physics Conference Series,202
0,1544(1):012112.
[6]	Di Wu, Chuanjiong Zhang, Li Ji, et al. Forest fire recognition based on feature extraction from multiview images[J].Traitement du Signal,2021,38:775-783.
[7]	Pei Song-wen, Fan Jing, Shen Tian-ma, et al.Research on Denoising Low Dose CT Image Using an Advanced Generative Adversarial Network with Multiple Generators[J].Journal of Chinese Computer Systems,2020,41(12):2582-2587.
[7]	裴颂文,樊静,沈天马,顾春华.面向低剂量CT图像的多生成器对抗网络降噪模型的研究[J].小型微型计算机系统,2020,41(12):2582-2587.
[8]	Pu Han, Tianqiang Huang, Bin Weng, et al. Overcome the Brightness and Jitter Noises in Video Inter-Frame Tampering Detection[J].Sensors,2021,21(12):3953.
[9]	Arnal, Josep, Luis Súcar.Hybrid Filter Based on Fuzzy Techniques for Mixed Noise Reduction in Color Images[J]. Applied Sciences,2020,10(1):243.
[10]	Weixing Wang, Limin Li, Fei Zhang.Crack image recognition on fracture mechanics cross valley edge detection by fractional differential with multi-scale analysis[J].SIViP,2022,DOI:10.1007/s11760-022-02202-6.
[11]	Songwen Pei, Xianrong Wang, Wei Qin, et al. STARS: Spatial Temporal Graph Convolution Network for Action Recognition System on FPGAs[C]//2021 IEEE 45th Annual Computers, Software, and Applications Conference(COMPSAC),2021,DOI:10.1109/COMPSAC51774.2021.00218.
[12]	Liang Zheng, Yi Yang, Qi Tian. SIFT Meets CNN: A Decade Survey of Instance Retrieval[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2018,40(5):
1224-1244.
[13]	Xing Jiangwa, Yang Pei, Qingge Letu.Automatic thresholding using a modified valley emphasis[J]. IET image processing,2020,14(3):536-544.
[14]	Bogdan Kwolek, Michal Kepski. Human fall detection on embedded platform using depth maps and wireless accelerometer[J]. sComputer Methods and Programs in Biomedicine,2014,117(3):489-501.
[15]	Wang, Yi, Jodoin, et al. CDnet 2014: An Expanded Change Detection Benchmark Dataset[C]//IEEE Conference on Computer Vision and Pattern Recogniti-on Workshops (CVPRW 2014),2014:393-400.
[16]	Zheng Wenbo, Wang KunFeng, Wang Feiyue.A novel background subtraction algorithm based on parallel vision and Bayesian GANs[J].Neurocomputing,2020,394(21):17
8-200.
[17]	Yan Yejin, Huo Wenxiao, Ou Jiaye, et, al. Improved SiamFC Target Tracking Algorithm Based on Anti-Interference Module[J].Journal of Sensors,2022.10.1155/2
022/2804114.
附中文参考文献：
[2]	谭嘉崴,丁其川,白忠玉.基于视频帧连贯信息的3维人体姿势优化估计方法[J].机器人,2021,43(01):9-16.
[3]	陈权,黄俊,徐访.改进视觉背景提取算法在室内的研究[J].小型微型计算机系统,2021,42(06):1250-1255.
[7]	裴颂文,樊静,沈天马,顾春华.面向低剂量CT图像的多生成器对抗网络降噪模型的研究[J].小型微型计算机系统,2020,41(12):2582-2587.

上理工版 新增：
相关参考文献：
经典帧差法 原版[3]
Chen Quan, Huang Jun, Xu Fang. Research on improved visual background extraction algorithm in indoor[J].Journal of Chinese Computer Systems,2021,42(06):1250-1255.

LBSP(改进背景减法) -> LOBSTER 改进ViBe
Zhang, Songsong, Jiang, Tian, Peng, Yuanxi, et al. A New Pixel-Level Background Subtraction Algorithm in Machine Vision[J]. Lecture Notes in Computer Science,2017,Vol.10463: 520-531.

一种融合 ＶｉＢｅ与多特征提取的微动目标检测算法
作者结合ViBe算法和LSBP算法提出LOBSTER( local binary similarity segmenter) 算法根据背 景复杂度自适应调整每个像素背景模型的更新策略，提高背景模型对动态背景的适应能力。
为实现前景微动目标的准确提取，克服提取过程中的高误检率等难题，对 ＣｂＣｒ分量、ＲＧＢ和 ＳＩＬＴＰ特征建 立背景模型，提出一种融合多特征的 ＶｉＢｅ背景建模改进算法。首先引入 ＬＢＳＰ算子，改进 ＬＢＰ－ＴＯＰ纹理编 码 方 式， 利用得到的纹理特征计算当前帧的时／空域前景 概 率，从而建立起接近真实背景的 ＣｂＣｒ背 景 模 型；然后结合局部像 素复杂度和３种特征的变化情况改进 ＶｉＢｅ判别与更新方法，利用背景减除和形态学处理得到完整的前景目标进行背 景替换。实验结果表明，所提算法能有效分割视频图像中的微动目标并实现背景替换。
杨春德,孟琦.一种融合ViBe与多特征提取的微动目标检测算法[J].计算机科学,2017,44(02):309-312+316.

GMM（背景建模）- VSLAM
Yamashita Y, Nishitani T, Yamaguchi T, et al. Software implementation approach for fingertip detection based on color multi-layer GMM[C].IEEE International Symposium on Consumer Electronics,2014. –> GMM
VSLAM method based on object detection in dynamic environments
Jia Liu
作者提出了一种基于GMM和YOLOv3的实时跟踪和映射方法。该方法利用ORB-SLAM2系统框架并改进其跟踪线程。它结合仿射变换矩阵来校正前帧和后帧，并使用GMM来建模背景图像和分割前景动态区域。然后，将获得的动态区域发送到YOLO检测器，以找到可能的动态目标。它在跟踪阶段使用改进的卡尔曼滤波算法来预测和跟踪检测到的动态对象。在构建地图之前，该方法过滤当前帧中检测到的特征点，并消除动态特征点。最后，我们使用TUM数据集验证了所提出的方法，并在动态环境中进行了实时增强现实注册实验。结果表明，本文提出的方法在动态数据集下具有更强的鲁棒性，能够稳定实时地注册虚拟对象。
Liu Jia, Gu Qiyao, Chen Dapeng, et al. VSLAM method based on object detection in dynamic environments[J]. Frontiers in Neurorobotics,2022,16, 10.3389/fnbot.2022.990453.

骨骼点相关 Alphapose
An Alphapose-Based Pedestrian Fall Detection Algorithm
作者通过输入大量跌倒姿态数据训练YOLOv4框选目标后使用自顶而下的Alphapose骨骼关节点提取关节点信息作为人体目标行为分析的动态特征变化依据信息进行行为分类数据。
Xiaodong Zhao,Fanxing Hou, Jingfang Su, et al. An Alphapose-Based Pedestrian Fall Detection Algorithm[J]. Lecture Notes in Computer Science,2022, https://doi.org/10.1007/978-3-031-06794-5_52.

卷积神经网络\时空卷积神经网络 CNN 
Title: A hybrid CNN and LSTM-based deep learning model for abnormal behavior detection
作者首先使用YOLOv3检测目标之后使用CNN根据视频帧进行目标跟踪从时间空间角度建模识别视频动态前景目标。
Chuanwang Chang, Chuanyu Chang,Youying Lin. A hybrid CNN and LSTM-based deep learning model for abnormal behavior detection[J]. MULTIMEDIA TOOLS AND APPLICATIONS,2022,81: 11825–11843.
Chang, CW., Chang, CY. & Lin, YY. A hybrid CNN and LSTM-based deep learning model for abnormal behavior detection. Multimed Tools Appl 81, 11825–11843 (2022). https://doi.org/10.1007/s11042-021-11887-9.

无监督学习 GAN
Fall Detection with the Spatial-T emporal Correlation Encoded by a Sequence-to-Sequence Denoised GAN
该文章提出一种基于生成对抗网络（GAN）结构模型，采用帧序列捕捉运动中时空变化属性来识别提取视频运动目标信息特征实现动态目标识别。
Weiwen Hsu, JingMing Guo, Chienyu Chen,et al. Fall Detection with the Spatial-Temporal Correlation Encoded by a Sequence-to-Sequence Denoised GAN[J].Sensors,2022,22(11):4194.
Hsu WW, Guo JM, Chen CY, Chang YC. Fall Detection with the Spatial-Temporal Correlation Encoded by a Sequence-to-Sequence Denoised GAN. Sensors (Basel). 2022 May 31;22(11):4194. doi: 10.3390/s22114194. PMID: 35684812; PMCID: PMC9185321.

