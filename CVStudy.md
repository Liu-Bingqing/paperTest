# 斯坦福-李飞飞课程
图像识别的问题：语义映象
图像识别的难点：视点变化、光影变化、变形、遮挡、复杂背景、组内变异（相同目标不同类别）
## 图像分类
### 挑战
由于识别视觉概念（例如猫）的任务对于人类来说相对微不足道，因此值得从计算机视觉算法的角度考虑所涉及的挑战。当我们在下面提出（不详尽的）挑战列表时，请记住图像的原始表示为亮度值的 3-D 数组：
1. 视点变化：对象的单个实例可以相对于相机以多种方式定向。
2. 规模变化：视觉类通常表现出其大小的变化（现实世界中的大小，而不仅仅是它们在图像中的范围）。
3. 变形：许多感兴趣的物体不是刚体，可以以极端方式变形。
4. 遮挡：感兴趣的对象可能会被遮挡。有时，只有对象的一小部分（只有几个像素）是可见的。
5. 照明条件：照明在像素级别上的影响是巨大的。
6. 背景混乱：感兴趣的对象可能会融入其环境，使其难以识别。
7. 类内差异：感兴趣的类别通常可以相对广泛，例如椅子。这些对象有许多不同类型的，每个对象都有自己的外观。
###  图像分类管道
1. 输入：我们的输入由一组N个图像组成，每个图像都标有K个不同的类中的一个。我们将这些数据称为训练集。
2. 学习：我们的任务是使用训练集来学习每个类的样子。我们将此步骤称为训练分类器或学习模型。
3. 评估：最后，我们通过要求分类器预测一组以前从未见过的新图像的标签来评估分类器的质量。然后，我们将这些图像的真实标签与分类器预测的标签进行比较。直觉上，我们希望很多预测与真实答案（我们称之为基本事实）相匹配。
### Nearest Neighbor Classifier
train output - test output - L1 distance metric(曼哈顿距离)判断差异
缺点：测试预测时间复杂度O(N)大于训练复杂度O(1)，但理想状态应是预测时间短语训练时间
### K-Nearest Neighbors
train output - test output - L1 distance metric(曼哈顿距离)/L2 distance metric(欧式距离)判断差异
缺点：在测试数据集上实验耗时，distance metric无意义
分类器必须记住所有训练数据，并将其存储起来，以便将来与测试数据进行比较。这是空间效率低下的，因为数据集的大小可能很容易达到千兆字节。
对测试图像进行分类是昂贵的，因为它需要与所有训练图像进行比较。
**超级参数选择**：取决于：数据集
将总数据集分割出一定比例的validation验证数据集可以有效验证分割比例超参
## Linear Classifier 线性分类
### 线性分类器
线性分类器将类的分数计算为其所有3个颜色通道中所有像素值的加权和。根据我们为这些权重设置的精确值，该函数能够在图像中的某些位置喜欢或不喜欢（取决于每个权重的符号）某些颜色。例如，您可以想象，如果图像两侧有很多蓝色（可能对应于水），则“船”类的可能性更大。您可能会期望“船舶”分类器在其蓝色通道权重中具有大量正权重（蓝色的存在会增加船舶的分数），而红色/绿色通道中的负权重（红色/绿色的存在会降低船舶的分数）。
### 数据预处理
所有图像都是使用的原始像素值（从0到255）。在机器学习中，对于输入的特征做**归一化（normalization）**处理是常见的套路。而在图像分类的例子中，图像上的每个像素可以看做一个特征。在实践中，对每个特征减去平均值来中心化数据是非常重要的。在这些图片的例子中，该步骤意味着根据训练集中所有的图像计算出一个平均图像值，然后每个图像都减去这个平均值，这样图像的像素值就大约分布在[-127, 127]之间了。下一个常见步骤是，让所有数值分布的区间变为[-1, 1]。零均值的中心化是很重要的，等我们理解了梯度下降后再来详细解释。
### Loss function 损失函数
### Softmax分类器
### 最优化
## 神经网络
## 卷积神经网络
## 练习1 Assignment1