# 2022年国外论文阅读调研
## 期刊
### ⭐⭐⭐1.基于时空特征和radon变换的人体姿态识别增强框架-多媒体工具和应用程序-Salma Aftab - 多特征向量+radon形状特征+分类器
#### Basic information
Title: A boosting framework for human posture recognition using spatio-temporal features along with radon transform
journal: Multimedia Tools and Applications Q3
#### 方法：
we propose a novel combination of a number of spatio-temporal features computed over human blobs in a temporal window. These features include aspect ratios, shape descriptors, geometric centroids, ellipse axes ratio, silhouette angles, and silhouette speed. In addition to these features, we also exploit the radon transform to get better shape based analysis. In order to obtain improved posture classification accuracy, we used J48 classifier under a boosting framework by employing the AdaBoost algorithm.The proposed algorithm is compared with eighteen existing state-of-the-art approaches on four publicly available datasets including MCF, UR Fall detection, KARD, and NUCLA. Our results demonstrate the excellent performance of the proposed algorithm compared to these existing methods.

我们提出了一种在时间窗口中对人类块计算的大量时空特征的新组合。这些特征包括纵横比、形状描述符、几何质心、椭圆轴比率、轮廓角度和轮廓速度。除了这些特征，我们还利用radon变换来获得更好的基于形状的分析。为了提高姿态分类的准确性，我们采用AdaBoost算法，在boosting框架下使用J48分类器。在四个公开可用的数据集（包括MCF、UR跌倒检测、KARD和NUCLA）上，将所提出的算法与十八种现有的最先进方法进行了比较。我们的结果表明，与这些现有方法相比，所提出的算法具有优异的性能。

提出利用各种基于时间、几何和形状的特征，包括：基于人类斑点（human blob）的边界框宽高比、边界框上半部分、几何质心、椭圆长轴和短轴与人类斑点比值、人类斑点的长轴与短轴之间的角度、连续帧之间每单位时间的轮廓位置变化。+ radon变换捕捉当前帧人物外观。
Radon变换通过计算不同角度的图像切片来提供基于形状的分析，这有助于以有效的方式区分不同的人体姿势。为了降低radon变换的维数，进行了主成分分析。让算法可以更稳健捕捉人体形状变化
为了获得更好的精度，J48分类器在增强框架下使用。
Boosting是一种组合不同分类器以提高集成结果的过程。在增强过程中，在完整的数据集上训练先验分类器，训练后的分类器以处理先验分类器的错误分类。因此，在训练后期模型时，先前模型预测较差的训练数据实例被赋予更高的权重。在我们的实现中，我们使用了Adaboost和J48作为基础分类器。增加算法跌倒检测实时性
#### 引言
摄像机用于记录人体姿势序列，并根据不同的形状描述符对姿势进行分类。当前研究中进行的工作属于视觉姿态识别系统的后一类。尽管应用广泛，但由于人体部位的比例变化、相机视图变化、复杂场景、杂乱背景、阴影和反射、携带的物体、遮挡和高度类内变化、衣服的颜色和纹理不同、照明条件和执行率变化，人体姿势识别是一项具有**挑战**性的任务[49]。
#### 相关工作
Foroughi提出综合时间运动图像和特征空间技术组合用于在异常步态、正常和跌倒活动之间分类
Foroughi H, Naseri A, Saberi A, Yazdi HS (2008) An eigenspace-based approach for human fall detection using integrated time motion image and neural network. In: 9th International conference on signal processing,2008. ICSP 2008. pp 1499–1503. IEEE.
**近几年**：
2019年，Kong等人[29]提出了一项基于三流CNN的研究，以检测多种人类活动，包括跌倒、行走、躺下、坐下、站立、蹲伏等。他们在MCF数据集上获得了98.0%的特异性。
Kong Y, Huang J, Huang S, Wei Z, Wang S (2019) Learning spatiotemporal representations for human
fall detection in surveillance video. J Vis Commun Image Represent 59:215–230.
2020年，Feng等人提出了一个复杂的场景跌倒数据集以及LSTM跌倒检测方法，以检测向后跌倒、向前跌倒和侧面跌倒等事件[14]。MCF的特异性为93.5%，URFD的F评分为93%。
Feng Q, Gao C, Wang L, Zhao Y, Song T, Li Q (2020) Spatio-temporal fall event detection in complex
scenes using attention guided lstm. Pattern Recogn Lett 130:242–249.
2021，Y oussfi等人提出了一种基于V2V-PoseNet模型的方法来检测2D人体骨架[70]。使用URFD评估所提出的方法，分别达到93%的特异性。
Y oussfi Alaoui A, Tabii Y, Oulad Haj Thami R, Daoudi M, Berretti S, Pala P (2021) Fall detection of
elderly people using the manifold of positive semidefinite matrices. J Imag 7(7):109.
#### 数据集
四个公开数据集：MCF、UR Fall Detection、KARD、NUCLA，实验采用10倍交叉验证。考察算法准确性、时间效率、性能统计度量（特异性和敏感性）
Multiple Cameras Fall (MCF) dataset[3]
uvinet E, Rougier C, Meunier J, St-Arnaud A, Rousseau J (2010) Multiple cameras fall dataset.DIRO-Universite de Montr ´ eal, Tech. Rep., 1350
UR Fall Detection (URFD) dataset[27]
Kepski M, Kwolek B (2015) Embedded system for fall detection using body-worn accelerometer and depth sensor. In: 2015 IEEE 8th International conference on intelligent data acquisition and advanced computing systems: technology and applications (IDAACS), vol 2, pp 755–759. IEEE
Kinect Activity Recognition dataset (KARD) [18]
Gaglio S, Re GL, Morana M (2014) Human activity recognition process using 3-d posture data. IEEE
Trans Human-Mach Syst 45(5):586–597
Northwestern UCLA Action dataset(NUCLA) [68]. 
Wang WJ, Chang JW, Haung SF, Wang RJ (2016) Human posture recognition based on images captured
by the kinect sensor. Int J Adv Robot Syst 13(2):54
#### 方法
1. 背景减法提取二值剪影
2. 时空特征提取 - 时空集合特征
   1. ✔️纵横比 Aspect retio：通过二值轮廓结果图计算纵横比（边框宽高比）
   2. 上部人体轮廓形状描述符：相较于下肢姿态变化显著
   3. ✔️人体轮廓几何形重心(质心)：位置特征
   4. 椭圆轴比率：椭圆轴比率通过取人体轮廓的协方差矩阵的较大和较小特征值之间的比率来计算。
   5. ✔️轮廓角：剪影角度是一种几何特征，有助于区分各种人体姿势，包括行走、坐、蹲和躺。在协方差矩阵∑的主特征向量和x轴之间计算轮廓角。角度值随姿势的变化而变化。在跌倒检测系统中，假设轮廓角大于135◦ 那么一个人是在向后跌倒，如果它小于45◦ 则一个人处于向前跌倒的姿势。图2显示了跌倒姿势的侧影角度从90◦ 站立时，68◦ 当秋天开始时，25◦ 当秋天结束时，0◦ 以躺着的姿势。
   6. ✔️轮廓速度：时间特征，视频连续帧之间每个单位时间目标位置变化
   7. ✔️基于radon变换的特征提取：图像矩阵在特定方向上的投影
3. 分类
   1. Boosting with J48分类器：使用J48分类器，AdaBoost分类算法。Boosting是组合不同分类器以提高整体结果的过程。自适应增强或简称AdaBoost，是一种引人注目的集成分类技术，最初由Y oav Freund和Robert Shapire于1995年提出[52]。AdaBoost的基本机制是逐步构建一个强分类器，该分类器使用任意数量的可能弱分类器的线性加权组合对整个训练数据集进行准确分类。该算法在弱分类器池上迭代移动。在每一次迭代中，从未挑选的分类器池中恰好有一个新的分类器与相关权重一起被提升到集合中。改进的分类器是最能提高现有集成性能的分类器。从本质上讲，每个提升的分类器通过正确地分类否则被错误分类的数据点来补充现有的分类器集合。为此，AdaBoost为当前错误分类的数据点分配了更大的权重42336多媒体工具和应用（2022）81:42325–42351[59]。AdaBoost由于其工作方式，在存在异常值和噪声的情况下，其表现往往不理想。然而，由于AdaBoost的通用性和简单性，它被认为是构建强分类器最容易使用的算法。
#### 未来展望
一个重要的未来方向是将深度特征与所提出的特征融合，以进一步提高性能。然而，如果没有目前稀缺的大型真实世界姿势识别数据集，从头开始的深度神经网络端到端训练可能是不可能的。
### ⭐2.不同策略检测姿势摇摆中潜在不稳定行为的比较-Sensors-Bruno Andò - 综述+传感器
#### Basic information
Title: A Comparison among Different Strategies to Detect Potential Unstable Behaviors in Postural Sway   
Journal: Sensors Q2
#### 背景
一个积极健康的老龄化（AHA）社会将是每个人都能从中受益的资源，而AHA情景的发展正在世界各地引起越来越多的兴趣[1]。保持健康的老龄人口可以降低对医疗服务的需求，同时支持他们的同辈。为了应对这一挑战，发起了若干倡议，促进全世界积极健康的老龄化。从公共卫生的角度来看，虚弱是一个多层面的问题，其原因是身心健康和功能状态的变化，以及缺乏社会和经济资源。功能下降通常与较低的社会心理状态有关，即社会孤立、营养不良和共病，这些都是虚弱的决定因素。跌倒及其预测行为，如姿势不稳定，是功能下降的主要原因。它们都在很大程度上导致了行动不便和过早住院。老年人并不是唯一受跌倒和姿势不稳影响的对象。患有神经退行性疾病（如帕金森氏病（PD））的人也会出现姿势不稳和随之而来的跌倒，通常是反复发生的，估计发病后一年内，每名反复跌倒者每年的跌倒率在4.7至67.6之间[2]。在研究和实践中制定了一系列预防跌倒的干预措施。其中包括跌倒风险因素的临床评估和治疗，如注重平衡和肌肉力量的锻炼计划、药物管理和视力检查。
预测不稳姿态和跌倒异常行为
#### 方法：主要对于传感器方面的综述
**基于DWT特征的神经模型方法**
本文提出了利用可穿戴传感节点以及基于阈值的算法或基于NF的推理系统来检测姿势不稳定的潜在状态的不同技术之间的比较。
这项任务具有战略意义，可以对老年人和受神经系统疾病（如帕金森病）影响的用户的姿势摇摆进行连续实时监测。
尽管在基于微控制器的架构中不容易实现，但NF推理系统的性能优于基于阈值的算法。尽管如此，一种方便的方法可以是通过实施数据融合策略来验证基于阈值的姿态摇摆实时估计，该策略利用专用（云）服务器上离线运行的NF推断。
所提出的分析鼓励进一步发展拟议战略。
在本文中，对分析姿势摇摆的不同策略进行了比较，目的是检测站立状态下的不稳定姿势状态，作为潜在跌倒的前兆。考虑了三种方法：（i）基于时间的特征阈值算法，（ii）基于时间特征的神经模糊推理系统，以及（iii）基于离散小波变换的特征的神经-模糊推理。该分析是在广泛的数据集上进行的，并利用了旨在评估上述策略提供的预测的准确性和可靠性的性能指标。所获得的结果证明了三种考虑策略在正确区分稳定和不稳定姿势状态方面的价值。然而，对噪声数据的鲁棒性分析突出了神经模糊推理系统相对于基于阈值的算法的更好性能。
### ⭐⭐3.用于异常行为检测的基于CNN和LSTM的混合深度学习模型-多媒体工具和应用程序-Chuan-Wang Chang - CNN+LSTM
#### Basic information
Title: A hybrid CNN and LSTM-based deep learning model for abnormal behavior detection
journal: Multimedia Tools and Applications Q3
#### Background
**传统的监控摄像机仅提供被动图像捕获、存储和回放功能，以记录事件的发生。当发生异常事件时，很难立即发出警告。特别是，传统的监测方法主要依靠人工。当长时间看多个监控屏幕积累的精神压力和疲劳会分散注意力，忽视事故的发生。因此，如果无处不在的摄像头能够与我们的智能监控技术相结合，将大大提高视频监控系统的价值。**
#### 相关工作
许多学者对视频监控中人类异常行为的分析/检测技术进行了大量的研究和实验。这些方法大致可分为两种，即基于模型的行为检测和基于场景密度和对象交互的行为检测
##### 基于模型的行为检测
需要设置异常行为判断条件，提取视频序列中运动目标的运动特征信息，将这些信息与判断条件进行比较，并建立正常行为模型。
分类方法可分为三类：有监督、半监督和无监督[33]。
1. 有监督的方法旨在通过标记的数据对正常和异常行为进行建模。已经提出了一些文献来检测视频中的特定事件。它们通常用于检测训练阶段预定义的特定异常行为，例如跌倒检测[45]、打斗检测[7、19]和徘徊检测[18]。
2. 半监督方法只需要正常的视频数据进行训练，可以分为基于规则的方法和基于模型的方法。基于规则的半监督方法旨在使用正常模式开发规则。然后，任何不符合此规则的样本都被视为异常。例如，Tani等人[46]u s e d r u l e通过基于本体的方法检测视频监控中的异常事件。Nguyen等人[36]提出了一种基于从形状特征中提取的规则的跌倒检测系统。在基于模型的半监督方法中，异常模式对应于偏离表示正常行为的模型的实例。隐马尔可夫模型（HMM）和高斯混合模型（GMM）是最常用的模型。Nannan等人[35]提出了一种使用高斯过程进行异常检测的方法。首先，使用HOF提取低级特征来描述模式运动。然后，建立高斯过程模型以生成正态行为分布，该模型用于检测视频中的异常。在Feng等人[15] ，深度GMM用于学习正常模式。
3. 无监督方法旨在从未标记数据中提取的统计特征中学习正常和异常行为。例如，Weiya等人[50]提出了一种基于特征空间和支持向量数据描述（SVDD）的无监督核异常检测框架。
##### 基于场景密度和对象交互的行为检测
多人或拥挤场景（不考虑）
#### 方法 - 基于CNN和LSTM的混合深度学习模型
**使用YOLOv3实现行人目标检测 - 使用混合深度SORT实现行人目标跟踪 - 使用CNN提取动作特征 - 使用LSTM构建异常行为识别模型**
提出了一种用于异常行为检测的深度学习模型，该模型使用对象检测技术YOLOv3来检测行人，然后使用混合深度SORT算法来跟踪行人，以从序列帧中获得跟踪轨迹。然后，使用卷积神经网络（CNN）提取每个跟踪轨迹的动作特征，并使用长-短期记忆网络（LSTM）构建异常行为识别模型，以预测异常行为，如跌倒、踢腿、拳击等。实验结果表明，该方法在不同的行为数据集中具有良好的识别率，并且能够满足实时监控的需要。
本文的**目的**是开发一种能够立即检测异常行为的监控系统。该系统**实时识别**和判断监控图像中行人的活动状态，实现对异常事件的主动检测。该系统可以有效地检测异常行为事件或潜在危险，以加强需要劳动注意的传统监控系统的局限性，并减轻安全人员的精神负荷。为了避免误判，当检测到的一定数量的异常行为达到预设阈值时，监控系统将触发警告机制并向监控器发送消息，以确保即时提醒和响应，避免更严重的后果。
首先，我们获取监控场景的流式图像，并将流式图像转换为连续的图片帧。我们使用物体检测技术来检测图片中的行人。由于异常行为通常是不规则和瞬时的，因此有必要跟踪每个检测到的目标。跟踪后，我们将获得每个目标的轨迹，然后使用CNN提取运动特征。然后将这些轨迹的特征输入到两层LSTM模型中，以获得异常行为的最终预测结果。图1显示了整个系统流程图。下面将介绍该系统中使用的重要技术，包括对象检测、对象跟踪和行为识别模型。
##### 模型结构
所提出的异常行为检测架构基于VGG-16网络，该网络包含10个卷积层以提取特征。卷积层之间有5个池化层，如表1所示。卷积层的第一层使用7×7卷积核来保留动作空间特征，剩余的卷积层大部分被3×3替换，这可以获得更细微的特征，以增强网络识别能力并减少参数数量。随着网络的深入，计算量将增加。为了避免这个问题，我们在使用更大的卷积核之前减少了输入通道的数量，例如7×7。第一层中的通道数量为32。在每一层池化之后，通道数量将增加一倍，最多可达512。在完成卷积运算的特征提取之后，将获得长度为5的特征向量。我们将其转换为一维向量，并将其输入LSTM网络[11，28]。我们提出的分类模型使用两层LSTM。第一层LSTM将把结果发送给下一层和下一个自己。这样做的目的是，我们希望将每次的输出信息作为训练数据输入到LSTM的下一层，同时作为训练数据输出到LSTM下一层中，同时将信息作为输入数据传递给下一个自己。最后，它通过全连通层，通过softmax获得每个行为类别的概率，并将最高得分作为识别结果。
### 4.一种基于轻量级子图的跌倒识别深度学习方法-Sensors-Zhenxiao Zhao - OpenPose骨架信息+多尺度时间卷积网络（MTCN）
#### Basic information
Title: A Lightweight Subgraph-Based Deep Learning Approach for Fall Recognition   
Journal: Sensors Q2
#### Background
据统计[2]，2020年，全球65岁或以上的老年人口已达到7.27亿，到2050年可能达到15亿。2020年，该年龄段的老年人比例为9.3%，2050年将达到16.0%。跌倒最可能的后果是骨折，这会导致身体残疾，这会妨碍独立生活的能力，以及对再次摔倒的心理恐惧。跌倒不仅会对老年人造成中度或重度伤害，还会给他们及其亲属带来情感负担和经济压力。面对这种情况，快速有效地识别老年人跌倒尤为重要。一方面，它可以及时提醒监护人寻求帮助，以减轻跌倒造成的伤害；另一方面，它可以节省公共医疗资源，减轻社会公共医疗负担
[2]World Population Ageing 2020 Highlights-the United Nations. Available online: https://www.un.org/development/desa/pd/sites/www.un.org.development.desa.pd/filesundesa_pd-2020_world_population_ageing_highlights.pdf (accessed on 29
October 2021).
由于跌倒行为数据相较于正常人体姿态数据较少，因此基于深度学习算法的跌倒行为判断算法出现过拟合问题
#### 方法
##### 方法总结
本文提出了一种利用**骨架信息**进行跌倒识别的基于**轻量级子图**的深度学习方法。利用**OpenPose**提取人体骨架信息，设计了一个**端到端**的轻量级子图网络。引入了子图划分和子图注意模块，以增加更大的感知场，同时保持其轻量化特性。还设计了多尺度时间卷积模块来提取和融合多尺度时间特征，这丰富了特征表示。
本文提出了**一种基于端到端轻量级子图的深度学习方法**，用于同时提取和融合关节信息，以获得更丰富的时空上下文信息，这为骨骼序列的特征表示提供了更多线索。
##### 特征信息
关节信+增加类型语义引导、自适应图卷积和子图注意力模块
##### 流程
1. 首先利用OpenPose获取骨骼数据，然后对关节的多个信息流数据进行融合和编码。
2. 其次，通过空间模块，将类型的语义添加到关节，并将整个图划分为多个子图，并通过引入子图注意力的自适应图卷积模块对空间信息进行建模。
3. 然后，它被输入到时间模块，该模块用于通过空间最大池（SMP）和时间最大池（TMP）来聚合不同帧中不同节点之间的信息。引入多尺度时间卷积网络（MTCN）来充分提取时间上下文信息。
4. 最后，通过softmax函数通过全连接层获得最终识别分数。
##### 算法
所尺度时间卷积模块（MTCN）
在时间模块中，空间最大池（SMP）和时间最大池（TMP）用于聚合不同帧上不同节点之间的信息。在时间建模中，以前的工作经常使用一维卷积来提取运动特征。考虑到相似的动作通过细粒度信息和跨多个连续帧的缓慢变化的运动来区分，我们设计了多尺度时间卷积网络（MTCN）来提取不同时间尺度的特征。具体而言，通过时间维度上卷积核大小分别为3×1、5×1和7×1的时间卷积处理不同时间尺度的分支，然后在不同阶段融合三个分支生成的特征。多尺度时间卷积有助于提取更丰富的上下文信息，这提高了模型的特征表示能力。输出表示为
##### 特点
该设计采用单流结构，将空间建模和时间建模分离，有利于骨架的时空信息表达，并降低了处理的复杂性。
人体骨架不仅包含关节点数据，还包含多模态数据，如关节运动信息流。这种多模态数据的充分融合可以确保构建全局自适应邻接矩阵，从而降低计算成本和模型复杂性，提高计算效率。
子图有五个区域，驱赶，左上肢，右上肢，左下肢，右下肢，头部
#### 实验
##### 数据
我们收集了NTU RGB中的部分跌倒数据和非跌倒数据，并使用OpenPose算法提取URFD和UP-fall检测数据集的骨架，以获得相应的3D骨架数据。在GPU上，算法算力要求超过摄像机自身算力
1. NTU数据集：由3台Kinect v2摄像机同时拍摄。它包含60种类型的动作，通常也称为NTU 60。在这个数据集中，所提出的方法通常使用两种协议进行评估：交叉主题（X-sub）和交叉视图（X-view）。X-sub包含40320个训练样本和16560个测试样本，划分规则基于40个对象，表明训练和测试集中的行为来自不同的参与者。X视图将摄像机2和3采集的样本作为训练集（37920个样本），摄像机1采集的样本为测试集（18960个样本）。特定节点的名称和数量彼此对应，例如，3个代表颈部，16个代表左脚，25个代表右手拇指，等等。我们从NTU收集了一些跌倒数据集，并选择了跌倒行为和类似跌倒行为作为样本数据，分别包含948项和4506项，包括跌倒、捡起、坐下、穿鞋、脱鞋和跌倒。
2. UR Fall Detection Dataset (URFD)：是由安装在不同视点的室外摄像机拍摄的人类活动序列的集合，包括30次跌倒和40个日常生活活动的视频片段。在本文中，我们只使用了30个跌倒序列和30个正常活动序列的RGB图像。我们使用OpenPose算法提取这对数据集的骨架。
3. UP-Fall detection dataset：在3次试验中，从17名年轻健康受试者的11次活动（5次跌倒和6次日常活动）中收集了UP Fall数据集，包括两个数据集，即基于传感器的数据集和基于视觉的数据集。特别是，这个数据集没有反映老年人摔倒的现实。基于视觉的数据集是通过在房间中固定前摄像头和侧摄像头来收集的，这两个摄像头分别提供对象的前视图和侧视图。在所提出的方法中，我们仅利用了横向相机视图，这反过来降低了计算复杂性。实验证明，与使用14个角度的两个相机传感器2022、22、5482 8的最先进方法相比，它足以达到可比的性能。与URFD类似，OpenPose用于提取UP Fall检测数据集的骨架信息。
##### 评估指标
灵敏度（召回）、特异性和模型准确性
### ⭐5.智能监控系统中用于可疑行为识别的有监督和无监督机器学习技术综述-International Journal of Information Technology-Kamal Kant Verma - 机器学习方向综述
#### Basic information
Title: A review of supervised and unsupervised machine learning techniques for suspicious behavior recognition in intelligent surveillance system   
Journal: International Journal of Information Technology Q1
#### 介绍
本文首先讨论了可疑活动检测和识别的常见方法，然后总结了主要基于SVM、HMM和ANN分类器的有监督和无监督机器学习方法，这些方法以前被研究人员采用，从单一人类行为建模到拥挤场景。接下来，本文讨论了用于人类正常和异常活动识别的系统模型，以及先前文献中使用的各种特征选择器和检测器。随后，对基准研究进行了审查，这些研究涵盖了相关领域、所拥有的关键点、特征学习和应用的全面最新方法。最后，对各种论文的实验方面进行了讨论，讨论了基本性能矩阵，如准确性，以及相关领域的主要问题、常见问题、挑战和未来范围。
不同的特征提取算法，如HOG、HAR、光流、FAST、BOW，以及一些统计特征，如平均值、标准差、均方根值、动能等，以前也被研究人员使用过。还讨论了一些基于有监督（分类）和无监督（聚类）学习的方法来检测和识别异常行为。一些有监督的分类器如SVM和神经网络以81%和99.7%的准确率解决了这个问题。除了这些技术之外，基于决策者的J48也被正确地（[99%的准确率）用于姿势识别，并且具有训练模型非常简单和轻量级的优点。
##### 视频监控系统
自动视频监控系统在许多领域都需要应用，如（1）国家边境安全防范渗透；（2） ATM和银行系统（3）犯罪调查（4）商业和工业用途（5）卫星和遥感系统。
#### 异常行为检测基本方法
视频数据 - 预处理 - 动态目标检测 - 区域特征提取 - 分类器 - 判断 - 报警
##### 特征提取
在模式识别和图像理解中，特征检测是指找到一些关键点或兴趣点的方法，这些关键点或关注点可以定义图像内容，如边缘、角落、纹理和斑点等。特征提取是一种简单的降维技术，其中大数据被减少为更少的特征，称为**特征向量**，因为大输入量具有更多的数据，但信息更少。因此，需要将大量数据转换为一些特征集。现在，选择正确的特征是解决关键问题的一项重要任务。表1给出了一些特征检测和提取策略以及它们发布的时间。
##### 分类器
分类是将模式划分为类的过程。此过程将输入数据分类为类的数量。这通常用于基于学习的模型将新测试的数据分类到类标签中。发现正常和异常事件通常是两类问题。在这篇文献综述中，我们讨论了研究人员使用的分类器的数量，例如HMM，它是一个序列分类器、神经网络、决策树分类器、规则库分类器、模糊分类器等。
#### 机器学习中监督和无监督方法
##### 监督学习
监督学习是一种学习方法，用于首先基于标记的训练数据训练模型，然后对属于任何一个类的新测试数据进行分类。监督学习是一个两步过程。在第一步（即训练步骤）中，它涉及基于标记的数据学习分类器，第二步是验证和验证或测试，其中新输入的数据与训练的模型进行测试。基于监督学习的异常检测可以分为一类问题或多类问题。在文献中，许多分类器用于将问题划分为正常或异常。例如，支持向量机用于两类问题。现在在下一小节中，将讨论用于检测异常事件的分类器的数量。
1. 支持向量机 SVM
2. 基于神经网络
   神经网络是一种用于视频异常检测的分类器方法，可以应用于单类问题和多类问题。在第一步中，我们基于标记的训练数据训练网络，称为训练或学习阶段，第二步是测试或验证和验证阶段，也称为测试阶段，其中对照学习模型检查新的测试数据。已经开发了各种类型的神经网络。
3. 统计
##### 无监督学习
基于无监督学习的方法对异常检测问题具有重要影响。这些学习方法没有任何先验知识，并且基于正常事件发生次数和异常事件很少或很少发生的原则。
#### 异常行为检测和识别系统模型
视频数据 - 预处理 - 动态目标检测 - 区域特征提取 - 分类器 - 判断 - 报警
#### 挑战、问题、未来工作
1. 异常检测技术的主要挑战之一是探索正常和异常活动模式。
2. 标记数据的可访问性，用于训练和测试用于异常序列检测和识别的模型。
3. 强烈区分正常场景和异常场景之间的界限。例如，在天气预报中，与正常值的轻微偏差可能被视为正常，但在医疗领域，与正常的轻微偏差将被视为异常。
4. 噪声
5. 处理由具有多类域的输入数据的处理所产生的复杂性。
6. 重配置硬件是处理最新深度学习模型的首要要求
7. 低分辨率、可变照明条件、杂乱环境、输入视频的质量和分辨率以及模糊和阴影等背景效果。
##### 数据集
数据集UCF101：最著名的动作识别数据集，包含13320个视频，分为101类。每节课包含100到200个视频。一些主要的数据集动作包括人与人的交互、人与物的交互、乐器演奏等。此数据集包含具有不同照明变化、可变闪电条件、姿势外观和不同视点的捕获视频。
HMDB51数据集:HMDB51数据集是另一个众所周知的数据集，包含来自各种来源的各种动作视频，如电影、谷歌和Youtube视频等。该数据集包含6849个剪辑，分为51类。每节课至少包含101个视频片段。一些动作类别包括面部微笑、物体与面部互动、身体动作（如跳跃、站立或坐下等）。数据集中出现的主要挑战是，视频剪辑是从不同的视角拍摄的，不同的照明会随着4–6个不同受试者的不同姿势而变化。
##### 未来工作
就未来范围而言，我们需要开发**更鲁棒**的检测和识别算法，该算法可以在遮挡、低照度变化、可变照明条件和阴影期间提供显著性能，并且还可以**处理高水平的噪声数据**。未来，研究人员应该更加关注在开发过程中**实时影响算法速度和性能的因素**。许多现有的算法都是通过只考虑单个人类行为建模的某些方面来实现的，例如眼睛运动、嘴巴位置的变化和鼻孔。它们可以通过考虑头部运动和步态等更多因素来实现。设计多相机系统的实时识别和相机校准仍然是3D计算机视觉未来研究的一个巨大挑战，因为它决定了场景结构。现有算法必须在未来的实时大型视频数据集上进行测试，以获得一致性和更好的准确性。验证过程必须持续几分钟而不是几秒钟。许多异常检测算法仅限于结构化视频场景。因此，新算法必须与**非结构化视频场景兼容**。除了上述建议之外，还有一些其他问题，例如阴影离人太近，太多人同时进入背景等。这些情况可以通过使用放置在不同位置的多个相机进行同步和处理采集的数据来解决。最后，由于深度学习模型在动作识别、语音和语言识别、康复工程、生物医学和游戏等领域的广泛应用，研究人员可能会使用深度学习模型来解决这些问题。深度学习模型的另一个优点是它们自动执行特征工程，这是基于机器学习的方法中最耗时的部分之一。
### 6.基于步态的人工智能应用综述-FRONTIERS IN ROBOTICS AND AI-Elsa J. Harris - 步态+人工智能人体异常综述
#### Basic information
Title: A Survey of Human Gait-Based Artificial Intelligence Application 
Journal: FRONTIERS IN ROBOTICS AND AI 
#### 介绍
我们对2012年至21年年中的已发表作品进行了电子数据库搜索，这些作品侧重于人体步态研究并应用机器学习技术。我们确定了使用步态数据的机器学习的六个关键应用：1）步态分析，其中通过使用人工智能算法改进了分析技术和某些生物力学分析因素，3）使用一人或多人跟踪和定位系统（如OpenPose、同步定位和映射（SLAM）等）的人体姿势跟踪，6）利用步态数据、模拟和机器学习技术重建人体运动的动画。我们的目标是对机器学习技术在步态分析中的应用进行一次广泛的调查，并确定未来潜在的研究和发展领域。我们讨论已经使用的机器学习技术，重点是它们执行的任务、它们试图解决的问题以及它们导航的权衡。
智能步态（SG）是指任何利用人工智能（AI）的综合人类步态数据分析系统。它是一个不断发展的研究领域，利用了现代传感技术、自动化、云计算、数据分析、并行处理和物联网（IoT）的进步。
机器学习技术被成功地用于改善步态分析的许多方面。在本论文集中，AI 1）帮助数据聚合和预处理，2）与另一个AI一起提高其性能、可解释性或准确性，3）对步态阶段进行分类并预测步态事件。
**步态**是软生物特征，可以通过步态识别人体特征。步态识别的主要应用是人识别、人重新识别、人身份验证、性别识别、年龄估计（Dindorf等人，2020a）、占用感知（Yang等人，2018）、人群密度估计（Zhou等人，2018年）、视频监控应用的人群监控和异常检测（Sun等人，2017年）以及多玩家跟踪和鉴定。
**意义**
步态分析有助于监测老年人的日常生活活动（ADL），以提高他们在家中和医院外的生活质量和健康护理。HAR使用可穿戴设备带来了四个主要问题，通常需要权衡：1）能源考虑因素2）活动识别准确性3）对不同用户和不同活动的鲁棒性4）用户体验。这些SG系统识别几种ADL，如弯腰、蹲下、行走、躺下、滚出床，以及它们之间的转换，以检测跌倒，最大限度地减少躺下与跌倒事件的错误警报，同时努力保持这些系统的低成本、自动、适应性和不引人注目。
### 7.RGB-D数据集综述-COMPUTER VISION AND IMAGE UNDERSTANDING-Alexandre Lopes - RGB-深度数据集综述
#### Basic information
Title: A survey on RGB-D datasets 
Journal: COMPUTER VISION AND IMAGE UNDERSTANDING Q2
#### 介绍
RGB-D数据对于解决计算机视觉中的许多问题至关重要。已经提出了数百个包含各种场景的公共RGB-D数据集，如室内、室外、空中、驾驶和医疗。这些数据集对于不同的应用是有用的，并且对于解决经典的计算机视觉任务（例如单目深度估计）是基本的。本文回顾并分类了包含深度信息的图像数据集。我们收集了231个包含可访问数据的数据集，并将它们分为三类：场景/对象、身体和医学。我们还概述了不同类型的传感器、深度应用，并检查了包含深度数据的数据集的使用和创建的趋势和未来方向，以及如何将其应用于研究单眼深度估计领域中可推广的机器学习模型的发展。
### 8.人类行为分析中数据挖掘和大数据的系统调查：当前数据集和模型-TRANSACTIONS ON EMERGING TELECOMMUNICATIONS TECHNOLOGIES在线发表-Xuefeng Ding - 人体行为视频数据集挖掘综述
#### Basic information
Title: A systematic survey of data mining and big data in human behavior analysis: Current datasets and models
Journal: TRANSACTIONS ON EMERGING TELECOMMUNICATIONS TECHNOLOGIES Q2
#### 介绍
Human Behavior detection - HBD
近年来，理解人类行为已成为计算机视觉研究领域最重要的课题之一。这种日益受到关注的原因是，该领域的研究成果可以带来广泛的应用。人类行为分析（HBA）包括从人类运动和动作检测到的广泛研究领域。
通过动作和人类活动的检测创建的数据集可以将不同的检测方法与相同的输入数据进行比较。数据挖掘和大数据方法在分析与人类行为相关的数据方面非常流行，可以用来应对快速处理的挑战。本文对HBA中的数据挖掘和大数据进行了系统的调查。我们关注文献中与人类行为模式检测相关的当前数据集和模型。这些文章根据数据集的重点分为五大类：对象检测、运动、动作、活动和行为。本文概述了HBA中的数据挖掘和大数据模型，以及基于这些类别的相关数据集，以突出未来工作的前景研究途径。

这些方法可分为三大类：模式匹配算法、19种机器学习算法、20种和对象检测算法。2特别是，视频中的自动人类跟踪一直是研究人员感兴趣的话题，因为它是一个具有多种应用的多学科研究领域。事实上，在一些新的研究领域，视频中人类自动跟踪的重要性正在增加，例如人机交互和虚拟现实。2一般来说，计算机视觉领域中的目标检测、运动、动作、活动和行为以及监控、检索和人机交互的应用具有重要意义。2近年来，已经产生了一个大型数据集来挑战这些领域的研究人员。2使用这些数据集可以比较不同的检测系统，因此它们的分析非常重要。本文研究了基于视频的HBA最重要的公共数据集，并帮助研究人员为其算法选择最合适的数据集。在这里，基于视频的HBA被分为五个级别：对象检测、运动、动作、活动和行为，这是首次从这个角度检查问题。随着物联网和密集计算等新技术的发展，HBA的数据量急剧增长。2与此同时，数据挖掘和大数据分析这些数据的方法变得非常流行。因此，本文对HBA中的数据挖掘和大数据进行了系统的调查。我们回顾了当前的数据集和相关模型，以分析和识别人类行为模式。为了实现这一目标，对2010年至2021期间发表的文章进行了审查。

今天，HBA在计算机视觉社区中变得越来越重要，它将应用程序用于视觉监视、视频检索和人机交互。近年来，人们开发了更复杂的数据集来描述人类的行为和活动，称为大数据。2使用此数据集可以将不同的模型与相同的输入数据进行比较。本文旨在更完整地描述HBA最重要的视频数据集。此外，我们还讨论了用于分析该数据集的数据挖掘技术，以突出未来工作的研究空白。同时，引入与人类行为相关的数据集可以帮助研究人员选择评估模型的工具。

这项工作的动机是检测HBA相关视频中的人体运动、动作和交互。

此外，我们寻求在各种应用场景中开发这些领域的用途。视频数据集中的HBA包括各种步骤，如预处理、分割、特征提取、降维、对象检测和分类。3这里，人类的行为模式被分为几个部分，以便可以容易地描述它们之间的结构相似性。当公众可以获得可用数据集的准确知识时，可以节省时间和成本。因此，研究人员的工作更容易识别数据集，主要重点是开发新模型，而不是收集信息。此外，通过识别和访问属性来生成新数据集的需求也较少。
##### 人体行为识别 HBD
**人体行为识别的金字塔级别：目标检测 - 运动 - 动作 - 活动 - 行为**
通常，HBA在四个级别进行检查，包括运动、动作、活动和行为。1然而，在处理这些级别之前，必须识别图像中的对象。因此，我们基于五个级别（即，对象检测、运动、动作、活动和行为）来呈现HBA。
##### ⭐⭐⭐HBD视频数据集
1. 目标检测数据集
该数据集包括MSRA-1000、ECSD、PASCAL-S、SOD、DUT-OMRON、Inria、Caltech、MIT、AFLW、MTFL、WIDER FACE、NYUD2和SUN RGB-D。
2. 运动检测数据集
WEIZMAN（事件和行动）、KTH、CAVIAR、ViSOR、IXMAS和K3Da
3. 动作检测数据集
Weizmann（2001年和2005年）和KTH（2004年）是第一批也是最知名的动作检测视频数据集。由9个不同的人执行的9个动作（弯曲、顶举、双腿向前跳跃、双腿跳跃、跑步、横冲直撞、行走、单手挥动和双手挥动）组成。
KTH包括6个动作（拳击、搬运、握手、慢跑、跑步和步行），由25个不同的人在4个场景中进行（户外、各种规模的户外、不同衣服的户外和室内）。然而，此数据集不具备在真实世界中表达人类行为的能力。
ETISEO数据集由INRIA于2005年开发。创建此数据集是为了提高视频监控算法的性能并减少它们之间的相互依赖性。该数据集中的视频分为五类，包括窗帘、建筑走廊、建筑入口、地铁和道路。好莱坞由32部电影的视频序列组成，其中有八种动作的注释。
UCF体育数据集专门用于基于匹配时间模式的基准算法。6数据集是从包括BBC和ESPN在内的电视频道收集的。UCF YouTube是为了区分动作和视频而创建的。6该数据集从YouTube网站收集，包括相机移动、物体外观变化、比例、条件和亮度。UCF50是YouTube动作数据集，提供更多动作示例。6奥林匹克运动会也是行动和活动组成部分的数据集。
VIiOR（2005）和VIRAT（2001）数据集由运动和动作分量的组合生成。6此外，ADL是在厨房场景中为低水平的行动而创建的。6MuHAVi包含用于评估动作检测方法的多任务视频数据。6该数据集是在具有挑战性的环境（崎岖的背景和街道照明）中使用多台摄像机收集的。表5中报告了其中一些数据集的详细信息。
4. 活动检测数据库
MSR每日活动3D数据集包含用于检测人类活动的三维数据。6该数据集由10个不同的人的活动组成，他们执行20个动作，每个动作对每个活动重复三次。运输安全管理局（TSA）数据集包括机场的许多不同视频活动（例如，飞机抵达和离开、乘客抵达和离开）。
VIRAT数据集由两个阶段组成。第一阶段由16个事件组成，这些事件在25小时的视频时段内广播，第二阶段由1个场景组成，持续时间为4小时。5该数据集是用于评估视觉事件检测算法性能的大规模视频资源。6此外，在VIRAT数据集中，有显示个人执行动作的短片视频。
PETS数据集解决了群体活动的问题，如公共空间中的人口图像分析。7该数据集包含来自真实环境的数据，允许研究人员评估各种检测技术。
IXMAS由11个动作和10个人（5男5女）组成，每个动作执行三次。7候诊室（WaRo11）数据集旨在描述具有大量复杂活动的真实应用程序的复杂性。7该数据集仅由一个人执行，并模拟了行动发生的等候室。奥林匹克运动会包含运动员进行各种运动的视频。6体育活动从YouTube序列中收集，包括16节体育课和每节课50个序列。创建此数据集的动机是使用人类活动的调度结构来检查运动建模方法。参考文献73中显示了使用奥林匹克运动数据对活动进行分类的方法。
在ViSOR项目中，摩德纳大学推出了一个注释和多媒体数据的在线视频监控库，从而产生了ViSOR数据集。该数据集也用于活动，是各种研究项目的有效支持工具。此外，CASIA于2007年由中国科学院制造。7该数据集包括不同角度的户外人类活动。该数据集的目的是研究如何使用复杂的三维模型处理视角的大变化。CASIA包括由24个不同的人执行的8种不同类型的人类动作。此外，为该数据集提供了7种类型的两人交互。表6中报告了其中一些数据集的详细信息。
5. 行为检测数据集
一般来说，人类行为是由行动、认知和情感三个组成部分组成的复杂互动。
好莱坞人类行为（HOHA）数据集包括32段视频的视频序列，注释了八种人类行为。这些行为包括接听电话、打开车门、握手、拥抱他人、亲吻、坐下、起身和站立。、
KTH数据集表达了人类的行为和行动。5该数据集包括25个人在四种不同场景中进行的6种人类行为。与HOHA数据集相比，考虑到2000多个序列，该数据集中的背景分割要简单得多。
MuHAVI数据集包括从多个摄像机获得的视频数据。6这些照片是在夜间灯光、街道照明和固定且不均匀的背景下拍摄的。在站台的每个角落，都嵌入了一台Schwan闭路电视摄像机。这些摄像头对7个人的16种不同行为进行了分类。
LiveLab Labs为全方位技术的数据收集提供了一个类似家庭的环境。LiveLab提供了两个数据集，包括PLIA1和PLIA2。PLIA1是允许进一步了解行为的数据集合。
PLIA2包括4小时的视频数据（红外和RGB），其中制定了共享家庭活动的主题。
INRIA圣诞节包含11个动作，每个动作有10名演员（即5名男性和5名女性）三次。每个动作仅由一名演员执行。
tum厨房数据集提供了低级厨房场景中的图像。表7中报告了一些用于行为检测的视频数据集的详细信息。
##### ⭐⭐⭐HBD相关模型
Kale GV, Patil VH. A study of vision based human motion recognition and analysis. Int J Ambient Compute Intell (IJACI). 2016;7(2):75-92.

在参考文献76中，深度学习方法已用于检测人类活动。这种方法的数据是通过**智能手机传感器**收集的。即使在活动数量未知的情况下，该方法也具有很好的性能。实验结果表明，当活动数量未知时，高斯模型可以高精度地识别活动。然而，基于哈拉巴兹指数的聚类数量，分层聚类是准确的。该方法的结果自动提供了对簇数量的适当值的选择，这最大化了活动检测的准确性。

参考文献77中总结了使用**语义特征**进行活动检测的高级方法。与低级特征不同，语义特征描述活动的内在属性。因此，工作的语义使检测更加可靠，特别是当类似的动作在视觉上不同时。作者定义了语义空间，其中包括最流行实践的语义特征，即人体、特征、相关对象和场景上下文。这里，利用这些语义特征的方法用于区分静态图像和视频数据活动以及四组活动（即，原子动作、人类交互、人类对象交互和群体活动）。

参考文献78分析了一个新的趋势。本文提供了监控领域的最新技术和新挑战的预测的**结构化快照**。这篇文章强调了计算机技术和社会学理论的相互作用。本次审查的目的是支持以下论点：社会视角基本上是用来对抗最高级别模块的。在这里，我们讨论了对人类活动及其收益的分析，以及如何利用社会信号实现价值。
### 9.基于转移的动作检测人体姿态估计的学习-Image, Vision and Intelligent Systems EI会议-Weida Lin - 
#### Basic information
Title: Action Detection Based on Transfer Learning of Human Pose Estimation
Journal: Image, Vision and Intelligent Systems EI会议
