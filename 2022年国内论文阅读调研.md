# 2022年国内论文阅读调研
## 硕士论文
### ⭐安防监控下人体异常行为检测算法研究-河北工业大学211双一流-张见雨 - 帧差法、图像数据数学矢量转换
#### 论文要点
基于智能安防监控技术
对跌倒、徘徊、打架的人体异常行为有效检测和预警
研究主要步骤：运动目标检测、运动目标跟踪及异常行为判断
    &emsp;&emsp;运动目标检测：基于均值背景与三帧差分法
    &emsp;&emsp;运动目标跟踪：多特征融合
    &emsp;&emsp;三种异常行为检测：其中跌倒行为根据运动目标重心降低及倒地时间较长特点，计算目标质心变化率、外接矩阵宽高和倒地时长 - **重点参考**
#### 论文框架
**绪论**：阐述研究背景意义、国内外研究现状、研究内容与论文安排
**运动目标检测**：常见算法、文章算法、实验、本章小结
**运动目标跟踪**：常见算法、本文算法、实验、本章小结 （不需要）
**人体异常行为检测**：常用方法、打架行为检测、**跌倒行为检测**、徘徊行为检测、实验、本章小结 （重点看行为检测方法和跌倒行为监测）
#### 异常行为检测
##### 基于相似度量的行为分析法
自主学习方法
首先 依照特定规则对待识别图像序列作分段处理
然后 从每个片段中提取相关特征
再次 将提取的片段特征组合连结形成整个视频段的矢量特征
最后 通过聚类及相似度方法对矢量特征分析，类别较少往往是视频中的异常行为
##### 基于模型的行为分析法
提前设置判定异常行为规则
首先 设置异常行为判定规则，依据规则分别提取目标颜色、轮廓、形状及运动方向等特征信息
然后 根据特征信息设定正常行为模型
最后 对视频图像逐帧与模型匹配，不匹配为异常行为
##### 基于状态空间的行为分析法
应用广泛，可以降低复杂场景中噪声对异常行为检测的影响
首先 标记视频图像序列中运动目标的姿态信息，对动态和静态姿态分别标记一个特定的节点或状态，通过概率联系
然后 遍历待检测视频的状态和节点，计算最大联合概率作为异常行为判定标准
#### 跌倒行为检测 - 重点参考
综合分析运动目标质心位移和速度变化，运动目标外界矩阵长宽比变化
运动目标质心不受旋转、伸缩和噪声影响
运动目标外界矩阵宽高比随着目标运动行为变化 - 固定阈值
### 公交车厢场景下的跌倒检测方法研究-北方工业大学-纪佳慧 - 深度学习，二阶段匹配算法、目标跟踪
#### 论文要点
自有数据集
深度学习 - 监督学习的静态检测算法 - 提出结合目标检测与姿态估计的方法，可解决遮挡严重、人员特征难以获取问题
    &emsp;&emsp;目标检测 - 边界框位置
    &emsp;&emsp;姿态估计 - 人体关键点位置，基于空间重合度融合
基于图片
    &emsp;&emsp;跌倒判别条件：人体目标检测边框的宽高比和空间位置
    &emsp;&emsp;判别网络：以人体关键点为特征，以人体骨架为输入，选择策略
基于视频
    &emsp;&emsp;二阶段目标匹配算法，关联多帧图像目标行为状态，累计异常帧数发出跌倒警报
#### 论文框架
**绪论**：研究背景及意义、国内外研究现状、技术路线、研究内容
三类跌倒行为检测方法：
1. 穿戴式传感器：需要每一个目标穿戴，成本高且穿戴繁琐
2. 环境设置传感器：基于地面震动传感器，采集信息干扰噪声较多
3. 计算机视觉
    &emsp;&emsp;**技术路线**：
    1. 目标检测与姿态估计：
    基于深度学习方法构建一种目标检测与姿态估计相结合的人体检测算法，实现人体整体特征和局部特征的全面获取。分别选取并训练目标检测算法和人体姿态估计算法，设计两者的融合策略，将两类算法的输出进行筛选和融合，再将模型部署并整合在便于移动的核心计算单元上，从而实现公交车厢内的人体检测任务
    2. 基于图片的跌倒检测算法：
    一方面，利用目标检测算法的输出结果设置跌倒判别条件，通过边界框的宽高比和空间位置判断是否跌倒。另一方面，将人体关键点作为特征，以大量人体跌倒骨架和正常骨架作为输入，通过监督学习方法训练跌倒判别网络，使网络具备自动识别跌倒行为的能力。在此之后，将跌倒判别条件与跌倒判别网络融合，设计结果选择策略，实现基于图片的跌倒行为静态检测
    3. 基于视频的跌倒检测算法
    从公交车厢场景的实际需求角度出发，对基于检测的目标跟踪算法进行分析，剖析其在公交车厢内部人员状态追踪任务中的适用性。考虑到算法的运行效率，选择基于检测的跟踪算法作为主要研究对象，对其原理及使用条件进行分析，根据公交车厢内部场景的实际情况，基于人体边界框的空间重叠度结合行人重识别方法提取人员外观特征，构造二阶段目标匹配算法，并将其作为人员行为状态追踪的主要工具。之后，将人体检测算法、跌倒检测算法及目标匹配算法进行整合，构成完整的公交车厢场景下基于视频的人体跌倒行为检测方法
**公交车智能视频监控系统**：系统框架，核心计算单元、软件环境、本章小结
**基于目标检测与姿态估计融合的人体检测算法**：目标检测相关算法和YOLOv5算法原理、姿态估计算法原理、实验、小结
    &emsp;&emsp;目标检测算法可检测出图像中指定类别物体的位置信息，可用于获取人的整体信息，人体姿态估计算法可以获取人体关键点位置信息和其构成的人体骨架，可用于获取人的局部信息，因此，二者结合用于描述人体的运动特征能够获得较好的效果
    &emsp;&emsp;文章使用YOLOv5
基于深度学习的目标检测算法主要分为两类：二阶段检测算法和一阶段检测算法。二阶段检测算法，又称Two-stage目标检测算法，由R-CNN[32] 及SPPnet[ 33]等Multi-stage目标检测算法改进而来，其处理过程包含候选区域生成和回归分类两个阶段，首先利用图像分割算法或卷积神经网络等方法生成候选区域，然后利用一系列分类算法对该区域进行分类和回归，从而获得较为精确的目标框。Two-stage目标检测算法中具有代表性的是Fast R-CNN[34] 及Faster R-CNN[ 35]等，虽然这些算法检测准确性较高，但由于算法相对复杂，导致处理速度稍慢。一阶段检测算法，又称One-stage目标检测算法，其原理是直接从原始图像中提取特征并通过回归分析的方式对物体的类别和位置进行预测，这种端到端的目标检测方法显著缩短了算法运行所耗费的时间。YOLO算法作为其中一类得到了广泛的应用。初始的YOLO算法 [36]通过不断改进和提高，在经历了YOLOv2[ 37]、YOLOv3[38]、YOLOv4[39]等多次升级和优化后，目前已迭代到至YOLOv5[ 40]目标检测算法，模型的准确性和实时性有了很大程度的提高。相比于其他版本的YOLO系列目标检测算法，YOLOv5的优点是其灵活性高，模型尺寸小，检测速度快，易于部署在嵌入式设备中，并且精度能够满足一般的应用需求。因此，在车载视频监控系统的应用中，本节选择YOLOv5作为用于目标检测的基础算法。
    &emsp;&emsp;文章使用人体姿态算法以ResNet-50[54]为主干网络进行特征提取
**基于图像的跌倒行为检测算法**：整体设计、人体检测跌倒行为判别、人体关键点跌倒行为判别、实验、小结
    &emsp;&emsp;人体的质心高度低于正常情况；颈部关键点的坐标小于下蹲时的最大高度；人体轮廓的最小外接矩形的宽高比小于一定值；大腿、小腿和上肢之间成一定的夹角；当人在公交车内身体向后跌倒时，手部与地面接触。
**基于视频的跌倒行为检测算法【重点】**：目标跟踪算法概述、二阶段目标匹配算法、实验、小结
单目标跟踪往往通过视频内初始帧的待跟踪目标的尺寸和位置，预测该目标在后续帧的尺寸和位置。相比于单目标跟踪，多目标跟踪需同时跟踪多个目标，并对相邻两帧之间的不同目标进行区分，将同一目标进行匹配，从而获得各个目标的连续运动轨迹。
**简单的在线实时跟踪方法(Simple Online and Realtime Tracking, SORT)**
文章选择IOU tracker作为主要研究对象，设计二阶段目标匹配算法
### ⭐-基于深度神经网络的室内人体姿态检测与异常行为判断研究-浙江科技学院二本-潘磊 - 深度神经网络
#### 论文要点
**目标检测方法** - 改进YOLOv5 - 优化网络结构，减少算力
**姿态检测** - 人体关键点在视频帧的时空分布角度
为减少算力参数量，改进YOLOv5，将原有的主干特征提取网络替换成G_CSP网络，增强特征层中的特征信息。在保留spp空间池化金字塔模块基础上引入注意力机制，优化了预测框的损失函数。
姿态判断 - 增加自定义多种类姿态分类，引入人体姿态估计辅助判断，从人体关键点在视频帧的时空分布角度判断
#### 论文框架
**引言**：研究背景意义、国内外研究现状、研究内容及章节安排
人体姿态检测分为两个步骤：人体区域检测和人体姿态分类
    &emsp;&emsp;**人体区域检测算法**：
    &emsp;&emsp;1. HOG特征提取算法主要有两步：特征提取和分类器，算法大致流程检测窗口滑动和计算图像梯度，从中我们很明显的看出HOG算法特征提取效率较低，完全靠颜色域上判别，对于图像上的噪声非常敏感，同时对于人物遮挡与行人移动幅度较大情况下难以判别，而SVM与Adaboost分类算法有着缺失数据太敏感，抗干扰能力较差的缺点。
    &emsp;&emsp;2. 背景建模算法：核心思想将静态物体作为背景，动态物体作为前景。背景建模的方法存在着动态行人有阴影干扰，导致检测区域污染，同时可以看出该方法会将静态的人物当作背景，只能检测出动态人物，忽略了静态人物。
    &emsp;&emsp;3. 二阶段模型：主要以高检测精度为主，可以达到像素级的检测，小目标检测效果较好。R-CNN
    &emsp;&emsp;**人体姿态估计算法**：
    &emsp;&emsp;1. 能量法
    &emsp;&emsp;2. 聚类法：二分类
    &emsp;&emsp;3. 重构法
    问题：传统的机器学习算法判断异常行为方法很多，但是传统算法的缺点也很多：1.异常行为的种类单一，大多数的异常行为是打斗、逃跑等激烈的群体性质动作，往往该异常行为发生频率较小，实用性不高；2.受众群体单一，传统机器学习方法依赖于运动行人轨迹，需要计算出速度特征信息作为判断的依据，导致静态人物异常行为无法判断，比如跌倒、吸烟、越线等；3.泛用性较低，每种异常行为需要对应一种检测算法，从上文看出大多数的传统算法都依赖当时异常环境下的一种或多种特征信息，若有一种特征信息丢失或者额外的特征信息加入，检测结果会受到影响，而大多数的异常行为各不一样，比如人群逃跑需要速度特征，而打劫、打斗需要激烈程度特征。4.分类的异常行为概念模糊不清，传统的机器学习方法只要检测出非正常行为就被判断为异常行为，明显不同环境下异常行为是不一样的标注，例如操场环境中跑步是正常行为，但是打斗是异常行为。
    &emsp;&emsp;4. 2D人体姿态估计：基于视频图像的二维信息，结果以图片的形式表现，其性能简单有效，初期成果就有很好的应用。**【重点】**
    &emsp;&emsp;5. 3D人体姿态估计：3D人体姿态估计相较于2D人体姿态估计多了一层深度信息，即人体到相机之间的距离，得到的最终结果是一个三维立体的检测图，三维的人体姿态估计可以增加更多的人物运动信息，以至于可以划分出更多的运动种类。
**监控系统的深度学习理论基础**：目标检测理论基础、人体姿态理论基础
多人姿态估计方法分为两种：一种是“自上而下”的方法，首先使用目标检测检出人体区域，然后在每个人体区域中分别检测关键点，进而估计每个人的姿态；另外一种是“自下而上”的方法，相反的首先检测图中所有的关键点，然后将关键点组合匹配，最后实现人体的姿态估计。从步骤上看出，自上而下的方法比较容易实现，但是多人场景有着物体遮挡、人物重叠的问题，往往自上而下的方法检测容易检测错误。
**监控系统中的目标检测**：介绍YOLOv5理论基础、改进YOLOv5、实验、小结
**监控系统中的姿态估计**：方案、实验、小结
本文的检测流程就是从视频中先提取人员区域，再从人员区域上做检测，其中关键点检测使用了“自上而下”的Alphapose多人物检测模型算法，为了加快检测速度，使用主干特征提取网络为Resnet50的Fastpose，提取人物14个关键点位置信息与置信度
ST-GCN算法：基于视频帧关键点序列变化判断姿态的深度学习算法



