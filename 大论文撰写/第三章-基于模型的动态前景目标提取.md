# 第三章-三 基于**模型的动态前景提取
监控视频数据由多张单帧图像组成，在短时段内随时间帧改变图像内容的图像序列数据，当连续变化的单帧图像帧率超过每秒24帧时，人眼因视觉暂留将无法辨别单幅静态画面以达到平滑连续视觉效果[27]。同时，监控视频中单帧图像之间具有较多动态关联性信息，对监控视频数据的研究实际上是对视频内连续单帧图像关联性和动态目标变化规律的研究分析。运动前景目标的识别和提取主要对视频帧图像中动态变化区域进行判定和提取[28-29]。监控视频存在大量背景信息和干扰信息，对关键目标和感兴趣目标的研究带来较多冗余特征信息，从而极大降低对动态人体目标的行为特征研究。因此，在行为研究和跌倒识别过程中需要进行视频动态前景目标的提取。
## 3.1 主流动态目标提取算法
（与模型相关的动态前景提取方法）说明动动态前景目标模型使用场景，理论基础以及动态前景目标模型的大致流程

本文的跌倒行为检测的目标对象是室内单目监控视频中的动态人体，首先需要针对监控视频数据中的动态人体进行动态前景提取，通常动态前景目标提取的流程图如下：
视频分割图像 -> 图像预处理 -> 建立模型 -> 动态前景目标提取 （待定）【动态目标提取流程图】
根据本文研究场景的特点，目前基于计算机视觉技术主流的监控视频动态前景目标提取算法分别有帧差法、光流法和背景减法。
### 3.1.1 帧差法
（相关原理）

帧差法(Frame Difference)【30-31】是较容易实现的视频动态目标提取算法，该方法根据视频连续帧间图像具有强关联性特点进行帧间差分提取帧间差异动态特征信息的过程。若监控视频中视频图像序列无运动变化信息或帧间目标变化不明显则基于帧差法提取的动态前景目标结果不明显，否则可以识别视频中动态前景目标区域。帧差法将图像间差异变化处理转化为数学公式差分运算，通过设定单一固定阈值对差分结果绝对值进行动态前景目标和静态背景区域划分。
假设监控视频数据在预处理阶段总共被分割为n张单帧图像(f^N=1,2,......,n)，对连续两帧图像间的灰度像素值进行差分运算，得到差分图像D^n，如公式():
【公式()】
其中(x,y)是图像像素点位置，f^n(x,y)和f^n-1(x,y)分别表示第n帧图像和第n-1帧图像的像素灰度值。然后设置固定阈值T分类分割差分图像D^n中的动态前景目标和静态背景区域，同时对分割结果进行图像二值化处理操作以强化视频动态前景区域效果。如公式():
【公式()】
其中，R^n(x,y)结果中的255像素值区域是帧差法判别为视频动态前景目标区域，0像素值区域是帧差法判别为视频静态背景区域。最后对动态前景目标区域进行连通性分析获得基于帧差法的视频中动态前景目标提取结果。
二帧差分方法一般适用于动态目标运动慢的视频场景，为应对运动速度快的视频研究者增加单帧图像差分来缩小大幅运动目标的时间间隔目标图像差距。【李秋林】【32】等人提出三帧差法进行视频中动态车辆目标检测，他们分别对连续三帧图像进行灰度值差分，然后对差分图像做交处理，最后使用固定阈值分割前背景区域，该方法可以检测到不同行驶速度的车辆信息。【张彩珍】【33】等人提出一种五帧差分与模板匹配融合方法，结合Harris算法提取像素特征值作为角点匹配提升差分准确性。多帧差分法提升在二帧差法上做出改进，使得算法可以在不同运动速度目标的视频场景中检测到动态目标，增加了帧差法的鲁棒性。多帧差分法的基本结构图如下：
【多帧差分算法结构图】
本文研究对象跌倒行为过程运动速度快且时间较短，
综上所述，帧差法原理相对简单、容易实现且可以快速检测提取视频中的动态目标。但是，帧差法对于运动迅速的目标提取效果较好额，而对于帧间运动目标变化小导致连续多帧目标位置重叠现象，差分结果绝对值一般被判定为背景区域从而出现“空洞”问题。因此，在监控视频动态目标提取过程中，需要对帧差法进行改进以及算法融合的方法提升基于帧差法的动态前景目标提取的完整性。

【⭐⭐如果在运动目标检测中使用帧间差分法，那么阈值的选取至关重要。阈值取值过小就没办法降低图像中噪声的影响；取值过大则会隐藏差分图像中运动目标的部分信息。如果将阈值设为固定值，则目标检测的结果极易受到场景中光线变化的影响。】
### 3.1.2 光流法
（相关原理）

光流法的物理概念是指空间内运动物体在成像上像素运动的瞬时速度【34】。人眼观察三维空间运动物体时，视网膜上产生一系列连续图像，类似于光线在视网膜上“流”过，被称为光流【35】。监控摄像机设备模拟视网膜原理，三维动态目标在二维空间运动成像原理图如图()
【图() 光流成像图】
三维动态过程投射到二维平面的运动场，其对应的视频图像序列就是光流场，在光流场中t时间间隔中像素点的灰度值为I(x,y,t)，利用连续时间间隔内的图像序列具有关联性计算像素点运动特征信息。
光流算法将三维运动目标转换为二维x,y轴两个分量的位移矢量：【】，通过堆叠水平分量和垂直分量表示t时间间隔内的光流场运动方向和速度[36]，假设该像素点在t时间间隔运动距离为(dx,dy)到视频下一帧图像，则在视频光照强度一致和三维空间不变的前提下，像素点灰度值变化在二维空间的投影如公式()
【公式()】
对上述公式进行泰勒展开得到公式()
【公式()】
结合公式()和公式()可得到公式()
【公式()】
为了简化公式，令【I^x=】，因此光流法算法公式如下：
【公式()】
从上述理论公式推导可以看出光流法通过分析光流场中像素点运动速度和方向获取三维视频中运动目标的位置变化信息，从而检测视频动态目标。
综上所述，虽然光流法对静态背景变化具有较强的抗干扰性，但是光流法抗噪效果差。光流法计算复杂度相较于帧差法较高，提高动态目标识别的耗时，并且对现实场景中光照变化非常敏感。场景视角改变和研究场景空间变化都会对基于光流法的视频动态目标提取结果造成影响。
### 3.1.3 背景减法
(相关理论)

背景减法的原理与帧差法类似【37】，首先选取无动态目标的背景图片用于构建背景模型，再读取视频中出现动态目标的当前单帧图像与背景模型进行差分处理操作，然后通过提取设置的固定阈值进行差分图像像素值判别，如果差分图像像素值大于阈值则算法判定该像素点发生位移，即为视频动态目标相关像素点，否则检测为静态背景并重新更新背景模型。最后，算法需要对阈值过滤后的判定结果进行二值化处理。基于背景减法的视频动态目标检测流程图如下图()
【图() 基于背景减法的视频动态目标检测流程图】
假设视频在预处理过程中被划分为N张单帧图像(N=1,2,......,n)，则背景减法中差分操作与帧差法一致如公式()，但背景模型是无动态目标的完全静态背景区域的存储图像集。
【公式()】
其中(x,y)是视频单帧图像的像素点位置，A^n(x,y)表示视频中第n帧图像，B^n(x,y)表示背景模型中第n帧背景图像。D^n(x,y)表示当前视频图像与背景图像差分的像素值。设置固定阈值T分割差分图像并对动态前景区域和静态背景区域进行判别结果二值化处理，如公式()。
【公式()】
为了进一步增加背景减法的视频动态目标完整性，【司海飞】等人【38】提出一种改进背景减法提取监控视频中动态前景目标轮廓，再进一步对目标外轮廓进行分析研究。他们提出一种最佳阈值法代替背景减法差分图像分割的固定阈值，进一步增加算法对动态前景目标提取的精准性。【Haifei Si】等人【39】提出一种仅检测跌倒行为的背景减法，他们通过分析实验场景下运动目标外边距以及重心变化将背景减法固定阈值设定为跌倒行为临界阈值从而判别视频中跌倒行为目标。
综上所述，背景模型构建和背景更新操作是直接影响背景减法对视频动态前景目标检测提取的关键步骤，背景减法仅适用于背景不变的实验场景，但是在本文研究场景中，实际室内监控场景存在光照变化、目标遮挡、跌倒行为运动过程时间短等诸多因素的影响，基于背景减法的视频动态前景目标算法对快速运动目标检测完整性和精准性低。同时，背景减法需要相同视角下静态背景视频数据和该场景下运动视频数据作为算法的输入数据，因此背景减法相较于帧差法要求硬件算力和算法耗时更高。
### 3.1.4 视频动态目标检测算法对比
根据上述视频动态目标检测算法的介绍，从算法性能进行对比如下表():
【表() 视频动态目标检测算法对比】
## 3.2 问题与挑战
（描述上述方法的特点和不足，动态前景目标提取方法的难点和挑战等）

与室外监控视频相比，室内监控视频包含较多静态冗余背景特征信息，若使用全域视频帧特征信息作为算法输入数据将降低算法识别实时性并对视频动态目标行为识别和行为研究造成干扰。室内监控视频的干扰源及噪声不同于室外监控视频数据，在室内单目监控视频场景中较为常见的干扰源是由于运动目标之间遮挡或室内光照不均等造成的阴影现象。同时，监控设备自身元器件问题或外界环境因素导致监控设备抖动并产生抖动噪声干扰，例如监控设备松动导致视频噪声或打雷天气造成设备抖动等。除识别异常人体行为前景目标外，在室内监控视频中正常人体行为动态运动速率缓慢，动态前景目标难以识别是基于视频监控识别人体动态前景目标的难点之一。
主流的视频动态目标检测算法对光照变化和不同背景场景视角敏感，抗干扰能力差。基于背景更新模型的前景提取算法因鬼影干扰导致算法精确度较低；基于特征提取的前景提取算法对全局特征进行提取，造成数据匹配冗余问题；基于神经网络的方法，一般需要对数据进行预标注，并且需要大量高质量的监控视频作为训练模型的数据支持，因此降低了前景提取算法的实时性和时效性，并且对视频单帧图像预标注操作无明确具体准则，则降低了算法检测结果的准确性。同时，大部分改进方法将数据处理作为前景提取算法的后续操作，将增加算法处理特征信息的时间和资源消耗从而降低算法的实时性。
因此，针对以上问题本文在近几年目标检测和视频前景提取研究基础上，本文通过分析室内单目监控视频数据和干扰源特点，对视频动态前景目标提取算法进行优化以更好的识别运动人体前景目标，减少背景动态区域特征和干扰源对视频前景目标特征分析的影响，提升后续分析和预估工作的效率和准确率，进一步提升时评动态前景目标提取算法的精确性和应用性。
## 3.3 本文方法
全域视频特征信息作为算法输入数据极大降低算法识别的效率和准确性，室内监控视频中正常动态行为运动速率缓慢和目标遮挡是动态前景目标识别的难点之一。本文提出一种特征定位与改进帧差法融合算法 (Feature Location and Improved Frame Difference Fusion Algorithm, HFID)算法减少背景静态区域冗余特征和干扰源对提取视频前景目标特征的影响。
### 3.3.1 模型整体设计
（模型整体设计和流程）
本文提出的基于改进帧差法的视频动态目标提取算法的基本过程：首先，对视频数据进行预处理，按帧切割视频形成单帧图片并对其进行降噪处理，主要去除室内单目监控视频的阴影和噪声干扰。其次，对预处理过的单帧图像进行灰度化处理以简化图像像素矩阵，提升本文前景提取算法的时效性和实时性。然后，利用目标检测算法对目标区域进行特征匹配并根据自适应差分阈值生成差分图像，对视频特征信息进行初步分割，去除视频中部分静态背景区以减少室内单目监控视频的冗余特征信息。最后，根据本文实验数据的特征设计构建改进帧差法，基于差分图像对前景目标进行精准识别和提取。整体结构图如图()
【图() HFID视频动态目标提取整体结构图】
### 3.3.2 数据预处理
本文分析研究场景得出室内监控视频存在两个主要干扰源：室内监控视频光照不稳定和抖动噪声。因光线变化，室内监控视频的阴影主要分为本影和动态阴影，本影是运动目标自身的阴影区域，而运动阴影[7]是前景目标运动时受室内光影影响在背景区域产生的投影。运动阴影在动态前景目标提取过程中被误判为前景动态目标，影响运动前景目标识别和提取的精准度。人眼视网膜可以根据视频像素亮度变化快速规避运动阴影干扰，判断视频中的动态目标。HSV颜色空间可以分离图像色彩像素的饱和度、色调和亮度，模拟视网膜感光原理判断颜色信息的方法[8]【40】。本文受此启发使用HSV颜色空间信息区分运动目标本影和运动阴影。背景阴影区域色调和饱和度与背景其他区域基本一致但亮度较低，根据像素级亮度变化判别本影和动态阴影。目前基于HSV阴影方法需要先分离背景前景区域，再使用三个分量值分别对比变化范围判断阴影像素阈值区间。
从二维信号角度分析，抖动噪声属于高频段信息，分析本文研究数据的噪声直方图可以确定抖动噪声是高斯噪声。本文使用高斯滤波算法处理抖动噪声，高斯滤波器根据像素点领域的像素加权均值代替该像素点的像素值，高斯函数[10]【41】具有可分离性实现高斯滤波器的有效性。高斯函数的傅里叶变化频谱是单瓣频谱，高斯滤波降噪是以目标像素点为中心建立窗口，计算其内部像素点均值并替换目标像素点的信号值，处理后的图像保留大部分图像信息且降噪过程不受高频信号的干扰。
为了提升算法实时性及数据处理速率将阴影消减和降噪处理进行同步处理。根据图像识别目标完整性和精确性判定区间当结果为1时，像素点是阴影部分和抖动噪声干扰信号，使用加权平均的方法用邻域像素点信息替代该像素值；连续帧处理迭代后，目标完整性和精确性判定区间区域稳定，此时RG(x,y)为0时，该中心像素点是前景目标自身阴影即本影部分。如公式()所示：
【公式()】
### 3.3.3 HFID模型
HFID模型的内部结构图如下图所示：
【】
本文对室内监控视频动态人体目标运动行为与时间序列视频动态前景目标变化规律进行分析研究，使用预处理过的视频连续四帧单帧图像作为算法输入数据，利用SIFT算法特征点定位后使用视频数据单帧图像动态变化信息自适应阈值算法最大类间方差法(OTSU)代替经典帧差法固定阈值判断方法生成差分图像。尺度不变特征变换算法(SIFT)对抖动干扰不敏感，并且对图像旋转、尺度变化、图像噪声和光照变化有良好的抗干扰性[12]【42】。若视频单帧图像有N个像素点，每个像素点邻域个数是8，像素中心点邻域单元所有尺度分布平均值是主导尺度，计算每个像素点单元计算8个尺度直方图梯度方向作为该中心像素点的SIFT描述子信息。像素点主导尺度和描述子信息作为帧间图像像素点差异对比参照信息构建特征空间输入KD树进行匹配度筛选， 去除帧间迭代像素点特征空间差异小的特征信息完成动态前景目标特征信息初步检测提取。假设基准图像样本S_i^f中有P_1特征点，当前单帧图像中有P_2特征点，二者的匹配点有P对，则第f帧和第f+1帧的特征点匹配度公式()如下：
【公式()】
OTSU算法[14]【43】是求图像全域阈值最佳算法，使用图像灰度分布均衡性的度量值方差作为阈值判断参数。本文基于OTSU算法原理和时序算法思路改进帧间阈值差分图像方法同时对实验连续输入图像E=\left\{E_i^n\middle| i\in F P,n\in i n p u t\right\}\bigm和基准图像S=\left\{S_i^f\middle| i\in p,f\in q\right\}使用类间差分，p表示基准图像样本集数量，q表示视频帧数。设置全局灰度阈值T划分基准图像和实验单帧图像集，即灰度级1~T 范围的基准图像A区域灰度均值占比与灰度级T+1~G-1的实验图像B^\prime区域灰度均值占比进行类间差分，灰度级T+1~G-1的基准图像B和1~T 的实验图像A^\prime进行类间差分如，再对实验输入图像A^\prime、B^\prime区域进行类间差分如公式(6)。灰度阈值T如公式(7)基于差分均值拟合更新以实现视频帧目标动态特征像素变化自适应更新帧间差分阈值，增加时序维度求类间差分最大阈值方法以实现随着时间帧变化动态更新最大差间阈值更新帧间差分阈值。
【公式()-()】
本文提出的融合特征点对齐和自适应阈值的改进帧差法流程如下：
1) 视频连续四帧预处理图像作为算法输入，与基准图像样本S_i^f作为动态目标特征匹配定位得到相关类间方差得到帧间最大差分集合，基于时间帧视频动态区域变化不断更新最大帧间差分阈值T_d^i。
2) HFID使用OTSU算法对经典帧差法差分图像中二值化阈值进行自适应阈值处理，该算法从像素级灰度值的差异调整全局阈值对图像亮度和对比度不敏感，从而根据帧间图像差分来调整阈值以提升算法的精准性。基于公式(9)分保留灰度差分值超过阈值的特征像素点，分别用D_1^{i-1}表示第f-1帧和第f帧之间的差分图像，用D_2^i表示第f帧和第f+1帧之间的差分图像，用D_3^{i+1}表示第f+1帧和第f+2帧之间的差分图像。
D_1=1,&D1i-1≥Tdi-10,&otherwise
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ D_2=1,&D2i≥Tdi0,&otherwise   ,i∈f
{\ \ \ \ \ \ D}_3=1,&D3i+1≥Tdi+10,&otherwise
(9)
3) 为了增强图像特征信息和提升HFID算法目标提取精准度，如公式(10)对差分图像集合D_i二值化处理。图像算术运算二值化图像集合D_i^\prime全组合或运算后得到形态学处理初始图像集合C_i，即C_{i-1}={Tre}_1^{i-1}|\ {Tre}_2^i, C_i=\ {Tre}_2^i|{Tre}_3^{i+1}, C_{i+1}={Tre}_3^{i+1}|{Tre}_1^{i-1}，目的是降低差分误差特征值损失。
&Tre1i-1=TRE(D1i-1)&&&Tre2i=TRE(D2i)&&Tre3i+1=TRE(D3i+1)
\ D_i^\prime=\left\{{Tre}_1^{i-1},\ {Tre}_2^i,{Tre}_3^{i+1}\ |\ i\in f\right\}	(10)
4) 对处理结果C_i^\prime进行图像形态学结果增强处理，包括开处理、闭处理、像素膨胀和腐蚀进一步提升HFID算法提取动态前景目标结果的完整性和精确性，得到结果区域H。本文利用图像开运算f\circ s=(f\odash s)\oplus s消除算法运算误差导致二值图像离散特征像素点及边缘粘连阴影噪声干扰像素点的问题，图像闭运算f\cdot s=(f\oplus s)\odash s和图像膨胀f\oplus s可以提升算法结果识别完整性消除帧差结果动态空洞区域但出现轮廓虚化识别精确性下降问题，调整结构元利用图像腐蚀f\odash s对目标区域像素边缘锐化以提升算法识别动态前景目标提取精准性。
## 3.4 实验与结果分析
### 3.4.1 实验设置
实验的基本硬件配置：CPU是 Intel(R) Core(TM) i5-1135G7 2.42 GHz；内存是16G、Windows 64位的操作系统；实验使用Python库。
实验使用基准数据集作为研究对象，并选取动态前景提取目标算法经典帧差法[13]、LOBSTER算法[3]【44】和3D-CNN动态前景目标算法[5]【45】作为对照算法，与HFID性能对比实验。LOBSTER算法[3]是【】等人提出的一种基于背景差值和背景模型更新原理的视频动态前景提取算法。3D-CNN是【】等人提出的使用YOLOv3检测目标后建立时空三维卷积神经网络提取视频动态前景目标。
### 3.4.2 对比实验结果分析
首先，本文选择基准数据集中的跌倒行为视频作为实验数据，对比不同算法对跌倒行为活动的检测性能，结果如表():
【表()】
【分析】
其次，本文选择基准数据集中的其他运动行为作为对比实验数据，对比不同算法对人体正常行为和类跌倒行为检测性能，结果如图():
【图()】
【分析】
## 3.5 本章小结
本章节首先介绍了目前主流的视频动态前景目标检测算法，根据这些主流算法的优劣势和研究数据分析提出目前室内监控视频动态前景目标提取的难点和挑战，然后提出一种融合帧间特征点定位和自适应阈值改进帧差法(HFID)的室内监控视频动态前景目标提取算法，阐述HFID的算法原理和构建过程。最后选择不同动态目标检测算法与HFID算法进行对比实验分析，HFID在老年人正常行为活动、类跌倒行为活动和跌倒行为活动的场景下都能达到精准实时提取的要求，符合室内监控视频中不同动态目标提取的要求。

