# 修改大论文框架处理记录
## 参考文献处理
v0.0.0.1 - v0.0.0.2 v1 v2 v3 v4
## 相关变更
### 摘要
821字
**关键字**：
目标检测 行为分析 跌倒行为检测 运动特征提取 时序信息 门控循环单元 Transformer
Objection detection, Behavior analysis, Fall detection, Time series, Gate Recurrent Unit, Transformer

关键词：目标检测 跌倒检测 门控循环单元 Transformer   
Objection detection, Fall Detection, Gate Recurrent Unit, Transformer

### 绪论
**页数**： 8页 7280
**1.2.2** 基于物联网智能家居的跌倒检测方法
基于物联网智能家居的跌倒行为检测方法主要是通过在智能家居中安装多个传感器，利用传感器采集的数据来判断老人是否跌倒，由于老人身体多处关节活动受限，因此需要对跌倒行为进行分类，识别出老年人是否摔倒。对此提出一种基于物联网智能家居的跌倒行为检测方法，利用支持向量机对采集到的数据进行分类识别，同时利用卡尔曼滤波算法对数据进行实时修正，最后再通过数据融合方法获取更加准确的跌倒行为识别结果。
本文中采用支持向量机分类算法，首先将数据划分为多个数据子集，每个子集有两个类别（支持向量机分类和卡尔曼滤波）。
**增加参考**
[]等提出一种基于Wifi的非接触式跌倒检测系统，通过嵌入式雷达家居物联感知室内动态目标行为活动规律和异常行为检测。
在这份调查报告中，我们提出了各种可以造福社会的Wi-Fi应用的建议，即通过检测生命体征和检测可疑物体。基于之前在该领域进行的研究，我们分析了使用Wi-Fi依赖技术的心率检测与基于传感器的旧方法的比较，以及现代实现的必要性，特别是在医疗领域。人们在任何情况下都可能有心脏问题，如心动过速和心动过缓，因此不需要接触的系统在检测生命体征异常方面是最实用的。基于传感器的系统可能仅依赖于Wi-Fi技术在系统中不同组件之间进行通信，例如在消息队列遥测传输系统中。然而，这些系统中的传感器可以被Wi-Fi技术所取代，以非接触式方式检测人员的存在并监测他们相应的心率。

此外，依赖Wi-Fi的系统，如Vital Radio和Wi-Sleep，可以同时监测多人的心率。

因此，基于Wi-Fi的非接触式系统在日常使用中是最有效和实用的。此外，尽管非接触式系统展示了技术进步的好处，但这些系统仍然可以进一步改进，因为它们倾向于在较短的距离内产生更高的准确率，正如超宽带雷达系统和菲涅耳模型所证明的那样。非接触式系统可以增强，在较长的距离内同时检测多个用户。在提供了需要接触和非接触式心率检测系统的细节之后，我们还提供了Wi-Fi技术的其他有用应用，例如在金属检测、人体跌倒检测等领域。
1.1 背景意义无变化
1.2 国内外研究现状
基于计算机数据的跌倒检测方法中加入原第四章的相关技术
1.3 内容 创新点 贡献 基本不变
1.4 不变
#### 表格记录
1.1 跌倒行为检测技术对比表 格式√


### 2 相关技术和场景定义
**页数**：11页 5628字
**2.3 场景定义**
是在三通道图像数据基础上增加深度通道数据，因此
利用嵌入监控设备摄像机的两个红外传感器和一个红外点阵投射器捕获室内环境中的深度图像，
#### 图片记录
- 已优化
2.1 多帧差分算法结构图 格式√
2.2 光流成像映射原理 格式√
2.3 背景减法流程图 格式√
2.4 RNN结构图 格式√
2.5 LSTM网络结构图 格式√
2.6 Bi-LSTM时序结构图 格式√
2.7 GRU结构图 格式√
#### 表格记录
2.1 研究样本数据集设计 格式√
#### 公式记录
2.1 - 2.24 格式√

**导师返修删除**
目前国内外许多研究者已经开始对轻量级可嵌套封装式跌倒检测算法进行研究，实现一种兼顾轻量化和精准性的跌倒检测算法相对困难，相信在不断分析研究中一定会在未来发现更多更有价值和应用性的跌倒检测算法，为推动人口老龄化社会卫生安全的发展做出贡献。

### 3 HFID
**页数**：11页 6619 **增加实验** 

全域视频特征信息作为算法输入数据极大降低算法识别的效率和准确性，室内监控视频中光影变化及抖动模糊噪声干扰是动态目标提取的难点之一。

根据图像识别目标完整性和精确性判定区间
**实验**
增加目标遮挡数据
增加不同拍摄角度实验数据
不同监控设备安装角度的室内单目视频
**评价指标含义**
召回率
特异性
综合评价指标
FPS
在视频动态目标提取实验中
召回率表示算法提取结果是动态目标数据在监控视频中真实为动态目标的样本占比
特异性表示算法提取结果非动态目标数据占监控视频中真实为非动态目标数据的比值
帧率用于评价算法在单位时间内处理视频图像的能力，验证算法运行耗时和实时性能。

**实验使用的对比算法**
选取动态前景提取目标算法三帧差法[23]、LOBSTER算法[50]和3D-CNN动态前景目标算法[51]作为算法性能对照组，与HFID性能对比实验
三帧差法 - [34] 李秋林,何家峰. 基于三帧差法和交叉熵阈值法的车辆检测[J]. 计算机工程,2011,37(4):172-174. DOI:10.3969/j.issn.1000-3428.2011.04.062. 34-23

【在帧差法2.2.1中出现】
LOBSTER算法 - [50] 陈树,丁保阔.动态背景下自适应LOBSTER算法的前景检测[J].中国图象图形学报,2017,22(02):161-169. 43
【在3.4 实验中出现】
3D-CNN - [51] CHANG C W, CHANG C Y, LIN Y Y. A hybrid CNN and LSTM-based deep learning model for abnormal behavior detection[J]. Multimedia Tools and Applications, 2022,81: 11825–11843. 44
#### 图片记录
- 已优化
3.1 视频动态目标提取模型整体结构图 格式√
3.2 HFID算法结构图 格式√
3.3 基于室内监控跌倒视频动态目标提取结果对比 格式√
3.4 不同运动视频动态目标提取结果对比 格式√
3.5 不同设备安装角度视频动态目标提取结果对比 格式√
#### 表格记录
3.1 监控视频动态目标提取主流方法对比 格式√
3.2 HFID算法主要步骤 格式√
3.3 不同视频动态目标提取算法性能对比 格式√
#### 公式记录
3.1 - 3.7 格式√
#### v0.0.0.3 改进
增加一个实验结果图3.4 并给出介绍分析


### 4 Transformer-EnGRU
**页数**：18页 7546字
#### 删除部分
本文通过分析实验数据中不同情况下的跌倒行为和非跌倒行为，将跌倒过程分为三个阶段：跌倒前、跌倒过程、跌倒后。首先，跌倒前阶段的特点是人体目标行为与正常人体行为相同，通常为行走、站立、坐着等情况，形体稳定甚至有时呈静止状态，如果一直该状态则可以判定为人体正常行为（Activity of daily life, ADL）。本文将跌倒前行为分为直立型跌倒前行为和坐蹲式跌倒前行为。然后，跌倒过程阶段的特点是人体动态行为变化最大，速度与加速度变化最明显的阶段，是跌倒判断过程中重要检测依据。在跌倒过程中，当人体目标处于直立型跌倒时，可能因直立滑倒或绊倒造成身体失衡出现倾倒。当人体目标处于坐蹲式时，可能因昏厥或抽搐导致人体前倾产生。当人体无法控制身体倾斜速度和角度时，身体进入跌倒下落过程，此过程中加速度和速度变化巨大达到峰值伴随头部、躯干、脚部变化。如何判断跌倒行为的开始是跌倒行为预测的难点之一。最后，跌倒后阶段特点是人体目标下落后撞击地面产生大量形变，对人体目标造成不定量伤害。特别是老年人群体在跌倒后往往出现躺姿状态，并持续一定时间。若人体目标在经过明显加速度和速度变化后久躺不起可以判定为跌倒后昏迷进行报警。

**动态目标特征信息分析与提取**
在日常生活中，人体动态活动主要分为正常活动行为、类跌倒行为和跌倒行为。正常活动行为主要包括行走、慢跑、锻炼等。相较于正常活动行为，类跌倒行为的形态变化更迅速且更接近跌倒行为，主要包括坐下、蹲下、弯腰、躺下等动态变化姿态。
**4.2.1**
Xu等人[56]提出一种使用OpenPose姿态估计算法计算关节点角度的跌倒行为分类检测方法，他们使用视频人体目标躯干角度变化表征运动行为，引用XGBoost分类算法判别视频跌倒行为。但是增加时间维度的骨骼点特征信息实际是三维动态变化信息，输入数据每添加一个维度可能导致算法处理效率和实时性大幅降低。张见雨等人[57]提出一种基于视频纹理、颜色和梯度多特征融合的时序动态目标跟踪方法，以当前时间点目标与历史记录模板的差异阈值作为目标行为的特征信息。该方式利用视频图像全域像素特征信息细致化分析时序间目标动态变化的相关性，但是该方法没有消除冗余特征信息对算法计算和时间的消耗。Merrouche等人[58]提出一种基于图像形态变化的特征提取方法，该方法通过分析目标区域的形态和物理特征构建轮廓变形描述子，通过提取视频动态目标轮廓的外接矩阵宽高比和质心特征，使用多分类核分析描述子实现跌倒检测。但该方式抗干扰能力较差，仅适合简单场景的跌倒检测。
正常人体动态目标外接矩阵宽高比特征一般用于判断动态人体目标是否为直立和躺下状态，并且在跌倒过程中宽高比值一般从低于0.5状态急剧飙升到高于1的状态【引用】。本文选择目标拟合椭圆长短轴比值代替常规人体动态目标特征信息最小外接矩阵宽高比表征，不仅可以判别正常老年人活动，还可以通过动态目标拟合椭圆的其他数学特性表征动态目标跌倒过程变化。【重复】
**4.2.2**  38页优化
**优化**
[61] 视觉Transformer与多特征融合的脑卒中检测算法 - 2022 58-58 删除

[56] Fall Detection in Elevator Cages Based on XGBoost and LSTM 2021 52-53
[57] 安防监控下人体异常行为检测算法研究 2022 53-54
[58] Fall detection based on shape deformation 54-55
**4.3.2**
主流Transformer目前主要应用于对单词语言序列数据相关性拼接的自然语言处理任务中，包括输入嵌入层、编码层、解码层、输出嵌入层和线性序列组合层。
**4.3.3**
监控视频帧间特征更新信息小使得时间上下文输出参数结果梯度小以及特征信息时序存储时间长，容易导致GRU模型出现参数训练梯度减弱甚至缩减为零的情况。

，每一个时间点特征信息在GRU门控制下计算获取该时刻的网络参数


本文对算法分类工作进行标签化处理，首先算法对常规人体行为不进行训练以节约算力和时间资源，如静态人体行为和走、跑等。然后，对类跌倒行为活动进行行为检测，通过特征信息判断是否含有跌倒趋势以进行预测，如果无明显跌倒趋势特征则检测为安全姿态，否则进行检测并提示。第三，算法对跌倒行为进行检测并提示。因此，从人体活动行为特点分析可以将跌倒行为检测复杂问题简化为基于计算机视觉的分类问题。

**Dropout**
Hinton等人提出，为防止小数据在复杂神经网络训练过程中出现过拟合问题，可以通过阻止特征检测器共同作用提升神经网络性能。Dropout为传统神经网络单元增加概率计算，减少神经单元对特征信息的训练迭代

将dropout加入隐藏层中，候选
在候选

**实验部分**

其中TP表示算法跌倒检测正确的样本数量，TN是样本类别为跌倒而算法检测结果是类跌倒的样本数量，FN表示算法类跌倒判别正确的样本数量，FP是样本类型是类跌倒而算法检测结果是跌倒行为的样本数量。

召回率表示检测是跌倒结果中真正跌倒行为样本与全部标签是跌倒行为样本的比值，该指标用于评估模型正确识别跌倒行为。特异性表示在模型检测结果是类跌倒行为中真正类跌倒行为的占比，该指标用于评估模型正确识别类跌倒行为。

召回率表示算法检测结果中真正跌倒行为样本的占比，用于评估算法正确检测跌倒行为的能力。特异性表示算法检测结果中真正类跌倒行为样本占比，用于评估算法正确识别类跌倒行为能力。

参数：输入特征维度、隐藏层大小、GRU堆叠层数（视频帧图像数量）
前馈网络入参：
input 
增加消融实验 - 使用
**实验一 暂定** 考察 单一GRU 无Transformer的多特征融合EnGRU 有Transfomer无改进的Transformer-GRU Transformer-EnGRU
实验一：Transformer-EnGRU跌倒检测算法消融实验
实验一通过控制算法环节，分别使用隐去算法主要步骤的对比算法与Tranformer-EnGRU实施进行消融实验，验证改进GRU跌倒检测算法性能是否提升，表【】是实验结果。
表4.4 Transformer-EnGRU消融实验结果对比

实验二 性能对比
实验三 不同运动场景下算法鲁棒性表现

v0.0.0.3
图4.11是实验结果分析。实验结果显示多分类Pose+Classifers算法和基于深度学习的时序特征处理Attention+Bi-LSTM算法和CNN+GRU算法鲁棒性较高，对不用视角下动态目标跌倒行为检测较准确，且对光影变化和遮挡物具有一定的抗干扰能力，而基于目标检测算法YOLO+Pose算法和跌倒行为历史模板Fall Module算法鲁棒性较低，动态目标被遮挡情况下检测不完整导致算法跌倒检测准确性下降。Transformer-EnGRU算法对于不同视角监控视频跌倒行为的检测精准性平均提升了0.11%，且对室内监控视频中光影变化和目标遮挡场景中检测精准性分别提升了0.04%和0.11%。因此，Transformer-EnGRU对室内单目监控视频不同视角下跌倒行为检测具有鲁棒性，且对室内监控视频中常见干扰源敏感性较低。

**实验使用的对比算法**
YOLO+Pose[15] 14-15
[15] Ke W, Xuejing L, Yang J, et al. Temporal action detection based on two-stream You Only Look Once network for elderly care service robot[J]. International Journal of Advanced Robotic Systems, 2021(18)

Fall Module[19] 17-19
[19] Towards a Template Matching Approach for Human Fall Detection 2021 19 - Chaudhari

Pose-trt[12] 46-12
[12] 基于 AlphaPose优化模型的老人跌倒行为检测算法 2022 46 - 13 12 - 马敬奇 - **Pose-trt**

Pose+Classifers[13] 48-13
[13] A Two-Stage Fall Recognition Algorithm Based on Human Posture Features 2020 48-14 13 - Han

Pose+ST-GCN[16] 64-16
[16] 基于多算法融合的跌倒行为识别 2022 64-17 16 - 陈淑红

Attention+Bi-LSTM[17] 62-17
[17] 基于Attention Bi-LSTM网络的跌倒行为识别 2021 62-18 17 - 陈勇

CNN+GRU[18] 65-18
[18] Fall Detection and Motion Analysis Using Visual Approaches 2022 18 - Xin
Transformer-EnGRU
#### 图片记录
4.1 跌倒过程动态目标像素点位移特征信息图 格式√
4.2 老人群体不同行为动态目标最优拟合椭圆 格式√
4.3 动态目标最优拟合椭圆长短轴比值对比折线图 - 优化 类跌倒行为在80和125之间指标波动大一些，sitFall在比值需要接近1，太极在1附近稳定波动 - 优化完成 格式√
4.4 动态目标最优拟合椭圆长轴与镜头水平线夹角正切值对比分析图 格式√
4.5 动态目标重心位移速度变化对比分析图 格式√
4.6 动态目标高度位移加速度变化对比分析图 格式√
4.7 动态目标像素级特征提取网络结构图 格式√
4.8 Transformer-EnGRU算法流程图 格式√
4.9 Transformer模型内部结构图 格式√
4.10 Multi-Attention Transformer多特征融合算法结构图 格式√
4.11 不同时序处理算法训练集loss和验证集loss变化对比图 格式√
4.12 不同时序处理算法测试集准确性变化对比图 格式√
4.13 不同跌倒情况下跌倒检测算法鲁棒性对比 格式√
4.14 跌倒检测部分结果图 格式√
#### 表格记录
4.1 基于计算机视觉跌倒检测主流方法对比 格式√
4.2 老人群体活动那个行为特点分析 格式√
4.3 En-GRU算法关键步骤伪代码 格式√
4.4 不同行为下跌倒检测算法性能对比 格式√
#### 公式记录
4.1 - 4.12 格式√


### 第五章 可视化开发
**页数**：9页  
**优化**
第五章 空白 47页空白 - 已去除 - 介绍更多关于可视化开发的相关内容
5.1 可视化设计
 - 5.1.1 架构层次设计 - 层次架构图
【阐明可视化架构层次结构】，通过哪些方法获取视频数据，数据通过什么传输到算法内，算法运算结果反映到可视化界面等
 - 5.1.2 开发流程设计
【阐述可视化开发流程，主要开发封装函数代码和主要步骤伪代码介绍】（5.2放在其中）
         介绍算法流程结构和主函数等 - 关键目标伪代码
为了设计开发更轻量化且更灵活的跌倒检测应用，本文使用可读性更强、更易编写的Python语言开发跌倒检测可视化界面，实现一款操作更简单，资源消耗更小的跌倒检测应用。表 是本文跌倒检测可视化界面开发和运行所需的软硬件要求。

本文使用Python主流开发软件Pycharm编写运行跌倒行为可视化程序和集成开发环境Anaconda3，在命令窗口使用“pip install”安装可视化开发库和封装算法的相关库。

独立封装获取监控视频方法、视频数据处理和跌倒检测方法和视图交互方法，

本文开发跌倒检测可视化界面设计中，支持使用者基于本地视频自主训练跌倒检测模型和基于已存在参数直接进行跌倒检测，并且支持检测本地离线室内监控视频数据和连接室内实时监控设备检测跌倒行为。本文受经典软件开发代码组织架构MVC（Model-View-Controller）架构【引用】启发，将数据计算模块层、视图开发和数据控制层独立开发，实现监控视频数据、处理视频数据算法和面向使用者界面分离的开发模式。

**暂定** 表.2是开发主要参数设计。图【】是基于MCV的跌倒检测可视化开发模块图。
【表5.2 主要参数】（暂定）【图 【】 暂定】
表【】是开发主要参数变量。【表 开发主要参数变量】 - **暂定**、
**暂定** - 基于MCV的可视化开发模块图

如果使用者选择自主训练模型，数据控制层接收使用者自定义跌倒检测算法参数，使用tkinter库中Entry方法接收界面输入存入算法参数变量【】【】，训练后使用【】保存至【】文件用于后续实时监控设备跌倒检测工作。如果使用者选择室内实时监控视频设备进行跌倒检测，数据控制层通过使用者设置【】参数连接监控设备，使用【】方法将视频图像信息传入计算模块层。如果使用者选择本地离线监控视频数据作为跌倒检测对象数据，数据控制层直接读取开发文件中【】路径中视频文件传输至计算模块层。表【】是数据控制层主要步骤伪代码。
【数据控制模块伪代码】

【数据计算模块实现】本文使用Python中OpenCV库对视频图像数据进行灰度化、降噪和计算差值获取视频动态目标操作。根据第四章介绍的特征提取方法分别提取视频动态目标区域的形态特征信息和像素级特征信息，并输入至多注意力机制Transformer算法中完成多特征信息融合，将其输入至基于GRU内部结构开发的改进GRU算法中完成跌倒行为检测。
**补充**
本文使用Python中numpy数据处理库和PyTorch网络构建库封装HFID算法、多注意力机制Transformer算法和改进GRU算法，对数据计算模块隐藏算法内部开发细节，根据不同操作数据计算模块直接调用算法函数，增强模块内部代码的可读性。s

在视频数据预处理

或者将主函数调用计算层方法用放在此处

【结果视图模块实现】

【本文设计开发的跌倒检测可视化界面支持使用者基于本地监控视频数据自主训练跌倒检测模型或根据已训练参数直接实施跌倒检测功能，并支持对本地离线监控视频数据和连接室内监控设备的实时视频数据进行跌倒检测。】


**小驼峰开发命名方式**


**优化参考**
第五章 可视化优化参考
2021 基于复杂场景的跌倒行为检测研究 - 重点参考
【需求分析、系统架构、系统实现（整体设计、系统展示）、本章小结】
2021 基于深度学习的居家老人跌倒检测研究_吕俊杰 - 重点参考
【系统开发环境配置介绍、功能架构（展示功能模块前端页面）、系统测试、本章小结】
2021 面向室内监控的跌倒时序检测研究及系统的开发_薛智元 - 重点参考
【系统结构设计、实现（数据采集和预处理伪代码，时序动作关键表）、前端界面展示】
2021 基于卷积神经网络的室内跌倒行为实时检测系统的开发
2022 基于深度学习的跌倒监测系统
2022 基于骨架信息的人体跌倒检测系统设计与实现
2020 基于多特征融合的老人跌倒行为检测算法研究_吴佳宝-CV+Sensor+模糊KNN
【系统框架、搭建过程、实时监测实验结果分析】

如果增加系统测试 - 暂定
可以直接说由于跌倒行为在现实生活中显少出现且具有随机性，数据采集较困难，因此本文使用第二章中构建的训练数据集

#### 图片记录
5.1 跌倒检测可视化界面内部层次结构 格式√
5.2 跌倒检测可视化功能模块图 格式√
5.3 跌倒检测可视化界面整体操作流程图 格式√
5.4 跌倒检测可视化主界面 格式√
5.5 连接本地监控设备界面 格式√
5.6 动作捕获界面 格式√
5.7 跌倒提示界面 格式√
#### 表格记录
5.1 跌倒检测可视化界面运行软硬件环境要求 格式√
5.2 数据控制模块主要开发步骤伪代码 格式√
5.3 数据计算模块主要开发步骤伪代码 格式√
5.4 视图交互模块主要开发步骤伪代码 格式√
5.5 运行文件主要开发步骤伪代码 格式√
### 第六章
**页数**：2页 1137字
优化

### 参考文献
**页数** 5页




## 注意
对4.3.3 继续优化 - 阶段性优化结束
优化4.2.2

摘要不少于500字

**较多空白**：
光流法第10页有空白 - 已去除
第三章 27页空白 - 已去除 - 补充对3.4的分析 28页空白 - 已去除
第四章 31页 - 已去除 32页 - 已去除 38页 - 已去除
第四章 39页有空白 很少 - 已去除

第五章 46页 空白 47页空白 - 介绍更多关于可视化开发的相关内容

实验数据集设计 加入部分数据集视频单帧图像 【暂定】


精准性表示模型检测是跌倒结果中真正跌倒行为样本与全部分类为跌倒结果样本的比值。召回率表示检测是跌倒结果中真正跌倒行为样本与全部标签是跌倒行为样本的比值，该指标用于评估模型正确识别跌倒行为。特异性表示在模型检测结果是类跌倒行为中真正类跌倒行为的占比，该指标用于评估模型正确识别类跌倒行为。


## v1内容
语言精修 公式、引用ok
1 2 基本内容不变，语言需要再精修
1 1-8 共8页
2 9-19 共11页
3 20-29 共10页 增加实验至11或12页
4 30-46  共17页
5 47-55  共9页
6 56-57  共2页

## v2改进 v3
添加参考文献和优化部分目录
语言精修 参考文献 隐去关键信息

用于验证算法提取动态目标的能力
**第三章实验增加** 
增加至11页或12页
实验环境精简
增加一张图片 单监控摄像机不同安装位置的跌倒视频 动态目标提取结果对比（部分）
图3.5中再增加含有遮挡物视频动态目标提取结果

**实验优化**
实验调整
1对不同行为动作室内监控视频动态目标提取准确性分析 - 使用原实验数据结果
2 对跌倒行为全过程视频提取准确性分析 - 使用原实验数据结果
3 对不同室内监控设备安装角度视频和干扰源的鲁棒性分析、、

**第四章改进**
增加至18页
4.2.2 适当增加内容
**第四章实验增加**
多特征融合后 分别使用时序信息处理方法LSTM GRU 和 EnGRU
增加损失递归折线图，对比主流时序信息处理方法与EnGRU算法对比（消融实验）
对比损失折线图 证明EnGRU算法轻量化和递归消减爆炸改进
增加不同行为（正常行为、类跌倒行为、跌倒行为-包括不同安装视角跌倒视频数据）检测结果图

增加不同行为动作检测结果 - 正常行为 类跌倒行为 跌倒行为及不同安装视角的跌倒行为检测结果


## v4
第五章优化删除部分
当使用者执行自主训练模型操作，本文基于tkinter库中get方法接收自定义参数isTrain并传入数据计算模块执行参数初始化和训练流程。
跌倒检测可视化界面全部功能如下：
（1）离线监控视频检测模块：离线待测监控视频上传功能，本地离线监控视频动态行为实时提示功能，本地待测监控视频跌倒提示功能。
（2）实时监控视频检测模块：本地实时监控设备连结功能，实时监控视频动态行为提示功能，实时监控视频跌倒提示功能。
（3）退出跌倒检测可视化界面功能。

表5.2 需要续表


**暂定**（暂不添加）修改：
规范伪代码写法 - 使用latex - 暂定
第四章增加一个消融实验 - 暂定
整理开发参数表 - 暂定

## v5
所有通过表格设置的图片，替换为表格


## 盲审注意事项
### 时间节点及流程
**上传小论文 已审核通过**
建模与仿真
ISSN Print: 2324-8696 ISSN Online: 2324-870X
期刊刊期：2023年第几卷第几期\2025年第几期 - 录用待发表不用填刊期
**查重**
**注意**：查重pdf格式提交
在4.28下午5点前填写论文答辩申请表   
截止日期 4.27 11:30
**ps**:盲审将直接使用查重版本论文进行盲审，故提交查重的论文版本需要使用盲审格式。
系统中提交的重合度检测论文将直接用于盲审送审，学生抽中盲审后无需再次提交论文。请在进行重合度检测时务必上传定稿后的完整论文（pdf版本）,论文须隐去导师及本人信息（用**或空白代替论文中出现姓名部分），抽中盲审后不受理版本变更。
**送审**
4.28 完成抽盲流程、4.29 30送审
**答辩**
答辩结束后材料报送截止2023年5月29日 上午11点前
材料：
学位审批表、表决表（夹在审批表第9页）、评阅意见表（夹在审批表第9页）、
学术小论文复印件(封面、封底、目录、论文首页)或录用通知书和论文稿件（夹在审批表第5页）
学术小论文复印件(封面、封底、目录、论文首页)或录用通知书和论文稿件（夹在审批表第5页）
人事简表
硕士：论文1本（装订版一本）
学术小论文复印件(封面、封底、目录、论文首页)或录用通知书和论文稿件（夹在审批表第5页）

**查重送审前需要把全文中有关本人、学校、导师的名字、信息全部隐去**
**参加盲审的每篇论文送1位同行专家进行评议，25个工作日内，评定结果总分高于60分并且其他分数均高于60分才能答辩**
否则
总分低于60分，需要对论文修改不少于3个月，学校评定完再送审
任意一项低于60分，需要对论文修改不少于1个月，送审
不同意答辩
**复审**
在初评结果10日内，提交书面复审申请。但复审仍不通过，需要修改论文不少于6个月