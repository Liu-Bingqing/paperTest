# 基于***的室内单目监控视频跌倒行为检测算法
## 主流基于计算机视觉的跌倒行为检测算法 √
### 阈值分析方法
基于阈值分析判断跌倒的方法是根据人体目标动态变化时形态特征信息值是否满足跌倒行为特征阈值来判断视频图像序列中是否出现跌倒跌倒行为，主流阈值分析方法使用数据特征提取信息的平均值、均方根或最值作为阈值基准。【Si】等人【45 Research on Video-Based Human Action Behavior Recognition Algorithms】提出一种多阈值分析检测监控视频跌倒行为的方法，他们首先在关键帧中提取动态人体目标，基于该前景动态目标通过物理公式转化提取其质心特征，通过时序变化总结归纳得到过程目标质心变化趋势和特点设置阈值从而检测出视频中的跌倒行为。【马敬奇】等人【46 基于AlphaPose优化模型的老人跌倒行为检测算法】提出一种基于骨架关节点信息的阈值分析法，他们利用AlphaPose姿态估计模型提取目标关节点信息并组合提取头部关节点线速度、胸部重心线速度、脚踝平均线速度形态物理算数特征，以及上半身中垂线域水平线夹角与时间阈值关系和下半身中垂线与水平线夹角与时间阈值关系，将实时的加速度或二次处理后的均方值等数据作为特征值，并与通过大量跌倒实验得出的阈值作比较，当数据值超过或低于阈值时判定为异常情况。基于阈值分析的方式易于实现且耗时短，但特征信息容易受到原始数据变化干扰，无法处理较复杂动态活动数据。
### 基于机器学习方法
基于机器学习的跌倒检测方法是构建二分类算法判断跌倒行为和非跌倒行为。经典的机器学习二分类算法有支持向量机（Support Vector Machines, SVM）、K邻近算法（K-Nearest Neighbor，KNN）、随机森林（Random Forest，RF）。【赵江平】等人【47 基于图像识别技术的不安全行为识别】提出一种基于SVM的不安全行为图像识别算法，他们首先使用滤波器进行图像预处理，然后提取动态目标的HOG特征和目标重心移动特征构建动态人体跌倒行为特征向量，最后使用支持向量机进行向量分类。【Han】等人【48 A Two-Stage Fall Recognition Algorithm Based on Human Posture Features】提出一种结合SVM、KNN、RF和决策树(Decision Tree, DT)分类器对正常行为活动和跌倒行为活动从【比较值γ、能量值ε、状态得分τ】对比值、能量值和行为状态得分进行聚类归纳检测跌倒行为。基于机器学习方法适用于小型数据集并且可以根据跌倒行为特征向量构建特点选择适合的分类算法，但是该方法易受光影和噪声干扰，对于复杂图像数据难以提取精准的跌倒表征信息，同时算法依赖手工标注数据特征信息。
### 基于深度学习方法
基于深度学习的跌倒行为检测方法是近几年计算机视觉适用广泛方法。主流方法有卷积循环网络（convolutional neural network，CNN）YOLO（You only look once）、循环神经网络（Recurrent Neural Network，RNN）和长短期记忆网络（Long Short Term Memory，LSTM）。|【孙博文】等人【49 基于卷积神经网络的室内跌倒行为实时检测系统的开发】提出一种基于卷积神经网络的跌倒行为检测算法，他们使用卷积神经网络中VGG-16对动作序列特征信息进行训练，并引用迁移学习的训练策略不断挑战损失函数权值来优化模型。|【吕俊杰】提出一种基于卷积神经网络的老人跌倒检测方法，首他使用Yolov3框选运动人体目标区域数据进行二次标注后作为卷积神经网络的输入数据对类跌倒行为和跌倒行为进行分类检测【49】。【潘磊】等人【50 基于深度神经网络的室内人体姿态检测与异常行为判断研究 2022】提出改进Yolov5进行视频动态目标检测，对Yolov5的原始网络模型架构改进注意力机制达到对网络结构进行压缩处理轻量化Yolov5网络结构，并优化原始损失函数减轻算法过拟合问题。【Chen】等人【51 An Approach to Real-Time Fall Detection based on OpenPose and LSTM】提出一种基于图像中人体相对位置参数的位移来识别人体跌倒的发生。他们基于OpenPose关节点信息捕获人体下降姿态与关节点的变化特征信息，同时考虑随时序推进关节点特征信息相关移动信息，使用时间序列的深度学习神经网络模型LSTM进行视频时序图像跌倒行为检测。基于深度学习的跌倒检测方法可以自主学习并获得更多视频图像特征信息，但需要大量数据作为训练参数以防止算法结果过拟合现象。
### 对比
根据上述对近几年国内外跌倒检测方法的分析，本文从方法实现、数据形式和应用场景三个角度进行对比归纳如表【4.1 基于计算机视觉主流跌倒行为检测方法对比】 √
【参考2022 老年人跌倒检测算法的研究现状】
## 问题描述与挑战【增加】
从跌倒行为特征提取的角度来看，本文主要对类跌倒行为和跌倒行为进行分类分析，类跌倒行为与跌倒行为的相似点在于，二者存在姿势的改变和躯干竖直与水平夹角变化，且人体重心在单位时间内发生明显位移，因此如何区分日常生活中类跌倒行为和跌倒行为是人体跌倒行为判断的难点之一。
从跌倒行为检测算法研究分析角度来看，根据上述分析因跌倒行为数据相较于普通正常人体姿态行为数据占比较小导致跌倒行为检测算法结果过拟合问题。同时，跌倒行为算法需要兼顾轻量性和实时性，能够实现嵌入式硬件应用和降低检测整体耗时是基于计算机视觉的跌倒行为算法新的研究点和挑战。
## 跌倒行为分析及特征提取 √
特征信息提取对于人体行为异常活动检测研究至关重要的，特征信息提取的方法和运用对跌倒行为检测算法性能具有极大影响。在日常生活中，人体动态活动主要分为正常活动行为、类跌倒行为和跌倒行为。正常活动行为主要包括行走、慢跑、锻炼等。相较于正常活动行为，类跌倒行为的形态变化更迅速且更贴近跌倒行为，主要包括坐下、蹲下、弯腰、躺下等动态变化姿态。与正常行为和类跌倒行为相比，跌倒行为过程的动作幅度和速度更剧烈且在短时间完成整个行为过程，具有突发性，其最显著的特点是在一瞬间人体目标的速度和加速度从零升至峰值再归零的变化。
本文通过分析实验数据中不同情况下的跌倒行为和非跌倒行为，可以将跌倒过程分为三个阶段：跌倒前、跌倒过程、跌倒后。
1. 跌倒前阶段：人体目标行为与正常人体行为相同，通常为行走、站立、坐着等情况，形体稳定甚至有时呈静止状态，如果一直该状态则可以判定为人体正常行为（Activity of daily life, ADL）。本文将跌倒前行为分为直立型跌倒前行为和坐蹲式跌倒前行为。
2. 跌倒过程阶段：人体动态行为变化最大，速度与加速度变化最明显的阶段，是跌倒判断过程中重要检测依据。在跌倒过程中，当人体目标处于直立型跌倒时，可能因直立滑倒或绊倒造成身体失衡出现倾倒。当人体目标处于坐蹲式时，可能因昏厥或抽搐导致人体前倾产生。当人体无法控制身体倾斜速度和角度时，身体进入跌倒下落过程，此过程中加速度和速度变化巨大达到峰值伴随头部、躯干、脚部变化。如何判断跌倒行为的开始是跌倒行为预测的难点之一。
3. 跌倒后阶段：人体目标下落后撞击地面产生大量形变，对人体目标造成不定量伤害。特别是老年人群体在跌倒后往往出现躺姿状态，并持续一定时间。若人体目标在经过明显加速度和速度变化后久躺不起可以判定为跌倒后昏迷进行报警。
### 跌倒动态物理特征信息分析提取 √
本文调研了近几年国内外基于计算机视觉的人体行为特征信息的主流表征方式，（例如目标外接长宽比、骨骼点角度、重心高度变化等）。【Xu】等人【52 Fall Detection in Elevator Cages Based on XGBoost and LSTM】提出一种使用Openpose骨骼姿态识别算法的关节点角度分类的跌倒行为检测模型，该方法根据识别监控视频中骨骼关节点位置信息，使用数学公式角度将视频人体姿态变化转化为躯干角度变化特征数据，引用XGBoost分类算法进行分类分析后输入LSTM算法中进行时序变化分析研究，最终判别视频中是否存在跌倒异常行为活动。但是，时序变化下的骨骼点信息的运算实际上是三维动态变化分析过程，算法输入数据每添加一个维度信可能导致算法处理效率和实时性大幅降低。将【张见雨】等人【53 安防监控下人体异常行为检测算法研究】提出一种基于目标的纹理、颜色和梯度特征融合的目标跟踪方法实时跟踪视频动态目标形成目标模板区域，以当前帧目标与历史跟踪目标模板的差异作为跌倒行为算法输入特征信息。该方式利用图像信息中大量像素特征信息更细致的分析时序间目标动态变化的趋势以及图像间时序相关性，但是该方法忽略了跌倒行为的突发性和短暂性，将跌倒前的目标正常动态行为跟踪信息也作为历史目标模板因此增加了模型运算消耗。【Merrouche】等人【53 Fall detection based on shape deformation 2020】提出一种基于图像形态学变化的特征提取方法，该方法通过分析目标的形态学和物理信息变化构建轮廓变形描述子，通过目标轮廓特征提取视频单帧图像的人体目标外接矩阵宽高比和质心，引用多分类核分析描述子时序变化过程并预测是否存在跌倒趋势。但是，该方式对于室内环境变化和视频视角变化敏感，仅适用于简单实验环境下的跌倒行为检测。
本文对目标提取数据转化为帧率为25帧每秒，视频时长为6秒的特征分析基准数据集合，选择目标外接矩阵宽高比【】目标高度变化速度【】、目标拟合椭圆离心率【】、目标重心移动加速度【】和躯干与水平夹角变化率【】5个主流的人体目标行为形态特征信息分析老人群体正常活动、类跌倒行为和跌倒行为活动对比如表4.2【老年人群活动行为特点分析】所示。
【表4.2 老年人群活动行为特点分析】√
从上表中可以明显看出，正常动态行为全程运动特征无明显变化且目标形态特性基本稳定，因此本文仅对类跌倒行为和跌倒行为进行分类分析研究。基于上述跌倒行为特征分析，本文选择目标拟合椭圆特征、目标重心运动速度和目标高度下降加速度作为跌倒行为目标分析特征信息。相较于目标外界矩阵，视频动态目标拟合椭圆可以提取更多关于运动目标时序关联性信息，本文基于目标拟合椭圆提取上短轴比值作为判别正常行为活动视频表征，提取椭圆长轴与镜头水平夹角作为跌倒行为和类跌倒行为差异表征。本文根据动态目标检测结果拟合最小外接椭圆部分效果如图【】所示。
【不同运动目标的外接椭圆图，标注长短轴和长轴与镜头水平夹角】
正常人体动态目标外接矩阵宽高比特征往往用于判断动态人体目标是否为直立和躺下状态，并且在跌倒过程中宽高比值一般从低于0.5状态急剧飙升到高于1的状态。本文选择目标拟合椭圆长短轴比值代替常规人体动态目标特征信息最小外接矩阵宽高比表征，不仅可以判别正常老年人活动，还可以通过动态目标拟合椭圆的其他数学特性表征动态目标跌倒过程变化。假设在时间间隔t_F（F=1,2,...,n）的最小外接椭圆长短轴比值K_F如公式（4.1）
【公式（4.1）】
其中动态目标拟合椭圆的长轴和短轴分别为a和b。如果视频单帧动态目标提取结果共N（N=1,2,...,n）个像素点，则动态目标区域最小像素点坐标为（），最大像素点坐标为（），则长轴与镜头水平线夹角【】为公式（4.2）
【公式（4.2）】
其中【】是动态目标拟合最小椭圆倾斜角度
运动目标重心随动态目标运动变化而移动，不受环境噪声和光影变化影响，同时也不会因监控设备位置视角不同而发生改变，重心的位移偏差和速度完全取决于运动目标自身，因此本文选择运动目标重心在时间间隔内的运动速度作为跌倒行为运动的表征。根据单帧动态目标区域D的重心（）如公式（4.3）
【公式（4.3）】
其中【】是动态目标区域像素值集合，则在时间间隔t_n+1~t_n内动态目标区域重心从（）到（）的位移移动速度如公式（4.4）所示
【公式（4.4）】
跌倒行为在第二阶段下落过程中，无论是站立式跌倒还是坐姿式跌倒都会存在目标高度急剧下降的过程，而下蹲、弯腰和躺下等类跌倒行为也同样存在下落过程，但下落速度变化相较于真正的跌倒行为相对缓和，因此本文选择目标高度下降加速度作为跌倒行为运动的表征之一，通过分析时间间隔内的目标高度下降速度变化程度分析运动目标是否为跌倒行为，单帧目标区域D的高度如公式（4.5）所示
【公式（4.5）】
则在时间间隔t_n+1~t_n内动态目标区域高度下降速度为公式（4.6），在该时间间隔内的动态目标高度移动加速度如公式（4.7）所示
【公式（4.6）】
【公式（4.7）】
以上根据目标形态变化特征信息将三维特征信息数据转化为二维时序变化趋势，三维特征趋势如图【】根据不同动作场景和监控设备视角提取的【】特征数据分析如图。
【图 不同动作场景下目标拟合椭圆长短轴比对比图】 - 默认水平方向为长轴，竖直方向为短轴
【图 类跌倒行为与跌倒行为夹角对比折线图】
【图 重心运动速度如公式】

椭圆特征参考
【这些特征包括纵横比、形状描述符、几何质心、椭圆轴比率、轮廓角度和轮廓速度。除了这些特征，我们还利用radon变换来获得更好的基于形状的分析。
A boosting framework for human posture recognition using spatio-temporal features along with radon transform 2022
】
【提出用两个不同的椭圆分别代表头部和躯干。分别从每帧的两个不同椭圆中提取长、短轴比、方向角和垂直速度三个特征，并融合成基于时间序列的运动特征。
A novel real‑time fall detection method based on head segmentation and convolutional neural network 2020
】
【Fall Detection Based on Dual-Channel Feature Integration 2020
然后，设计双通道滑动窗口模型，提取人体的动态特征(质心速度、上肢速度)和静态特征(人体外部椭圆)。】
【Human body fall recognition system 2020
宽高比、椭圆方向、椭圆长轴】
【2020 视觉屏蔽态视频监控中的室内跌倒行为检测研究
人体轮廓最小边界矩形框、椭圆形（主副轴、离心率）、骨架节点、对噪声不敏感但是易受拍摄角度影响】
### 基于卷积神经网络的像素级特征信息分析提取 √
单一根据目标提取结果的形态变化提取目标运动信息特征一般会导致跌倒检测算法灵活性和鲁棒性较差，目标检测结果时间域像素值间同样具有帧间关联性信息，因此本文引用卷积神经网络（convolutional neural network, CNN）提取视频单位时间内连续四帧动态目标提取结果图像的像素特征信息。卷积神经网络与多层感知机都是通过各网络层接收上一层权值运算信息逐一归纳输入原始数据信息的前馈神经网络结构。卷积神经网络的每层神经元网络相互独立极大降低算法的时间耗时和运算难度，并且卷积神经网络卷积层的权值信息可以在整体网络层次中共享传递从而极大降低权值运算和训练回馈损失运算难度，同时在卷积神经网络末端加入全连接层可以实现将图像三通道像素矩阵数据格式转化为一维特征向量形式用于后续对其进行分类分析研究。相比于多层感知机，卷积神经网络局部连接和权值共享的特点使得其在面向图像处理和图像像素级特征提取时可以捕获更多图像通道数据信息且达到特征信息数据降维处理的目的。为了更好的分类检测大量彩色三通道图像数据，研究人员后续提出LeNet-5算法】。本文引入卷积神经网络提取监控视频连续四帧动态目标提取结果数据的像素级特征信息以扩展目标形态特征，其结构如图【4.7】所示。
【图4.7 动态目标像素级特征提取网络结构图】
首先，根据形态特征信息分析选择基准视频数据中第90帧到125帧时间间隔内的单帧视频图像并统一将动态目标提取结果图裁剪为32像素×32像素的动态目标输入数据。
然后，将输入数据传入第一层32×32×4，过滤器大小为8的卷积层得到第一层的特征映射矩阵作为下一层的输入，设置第二层16×16×4，过滤器大小为4的卷积层和4×4×8的最大池化层提取动态目标区域的像素纹理特征信息，整个网络层均使用ReLU函数作为网络激活函数保持图像特征信息提取过程中非线性数据类型特点。
最后，使用全连接层将连续四帧动态目标像素级特征信息数据转化为特征信息向量数据。
## 融合transformer多特征时序递归神经网络的跌倒行为检测算法
### 整体算法结构
### 基于transformer的多特征信息融合 √
【transformer介绍】transformer【55】网络模型结构是基于注意力机制的深度学习神经网络结构，其基本网络结构包括编码器和解码器如图【】。深度学习中的注意力机制函数的作用是描述输入数据的特征信息，将其加权映射为输出特征向量。在标准transformer中的注意力机制模块仅输入两个矩阵信息，特征融合维度如下公式（）：
【公式（）】
本文根据transformer可以进行双矩阵特征融合的思想，使用多头注意力机制函数对监控视频动态目标对象的形态特征和像素级特征多特征信息进行多特征融合，并加入时序编码作为每一组动态目标特征信息标记信息进行同步编码操作获得监控视频动态目标时序多特征信息向量。【Vaswani】等人【55】在2017年提出多头注意力机制模型如公式（）：
【公式（）】
【JURAEV】等人【56 Exploring Human Pose Estimation and the Usage of Synthetic Data for Elderly Fall Detection in Real-World Surveillance】提出一种基于时序目标姿态序列的老人跌倒检测方法，他们将时序关节点姿态数据作为Transformer网络输入通过多头注意力机制提取目标时序姿态变化特征再使用分类机器学习算法检测出跌倒行为。本文根据研究数据的特点分析，监控视频数据的动态目标形态特征数据和像素级特征信息的提取均随时序维度存在变化趋势其时序间信息变化存在规律性和相关性，因此引入transformer网络进行单位时间间隔内多特征融合，重构图像特征信息以简化跌倒行为算法运算过程和复杂度，实现具有轻量级的跌倒行为检测算法。特征融合流程图如图【】。
【图】
从图中可以看出，基于transformer的视频动态目标多特征融合模块主要包括特征信息输入层，编码层和特征融合输出层。【】表示动态目标像素级特征编码，【】表示特征融合编码，【】【】【】分别表示视频动态目标形态特征的最优拟合椭圆长短轴比值特征编码、重心移动速度特征编码和高度位移加速度特征编码，【】表示时序编码。本文使用上文中基于卷积神经网络提取的视频动态目标像素级特征向量信息，使用监控视频连续四帧动态目标提取区域形态变化特征信息平均数值作为研究目标形态特征编码输入，如公式（）。
【公式（）】
## 模型 引入Transformer多特征融合改进GRU的跌倒检测算法
### 整体流程
视频图像信息的本质与语音数据、一段文字等时序相关数据类似，在时间维度上数据呈现顺序相关性。本文通过对处理时序数据相关算法的研究分析，构建图【】的Transformer-EnGRU跌倒检测算法。
### 特征融合轻量级图神经网络的跌倒行为算法 √
【LSTM网络是递归神经网络RNN的改进，增加了C控制参数用于决定时序信息是否被保留或被遗忘，门单元是一种让信息选择式通过的方法，一般使用sigmoid神经网络层和一乘法操作。输入数据与前时序信息进行关联性计算，判断是否丢弃前序信息以简化算法运算消耗。第二部分则是保留的前序信息与当前时间序列信息进行计算，形成新的控制参数用于更新时序集合信息】
【当要从连续图像序列中捕捉行人运动时，可能存在许多重复的或稍微不同的运动帧。由于大多数异常行为都是突然发生的，并且在身体运动中有很大的变化，因此差异非常小的连续帧可以被视为冗余帧。因此，有必要给这些连续运动帧一个姿势名称，作为异常行为的代表动作，并删除冗余帧。在本文中，我们从8个跨步中提取一个片段序列，并从序列中选择5个帧作为表示异常行为的动作序列，如图所示。5。】
### 改进门控循环单元（EnGRU）的跌倒检测算法 √
【视频时序数据特点】
时序数据是在时间段内一组按照时间维度顺序存储的序列信息。监控视频数据是一组单帧图像按照视频时间戳顺序排列的时序图像徐磊数据。【李登山】中在文中对视频数据时序特点进行分析总结，视频时间序列数据的关联性主要体现在视频单帧内和帧间的关联性，待检测目标区域的位置、大小、形状和像素等信息随视频帧间变化，而背景区域的特征信息随视频帧间几乎不变，因此视频帧间不同单帧图像的关联性信息包含时间上下文信息和空间上下文信息，视频的时序信息特征实际上就是视频的时空上下文信息【58】。
本文在上文中介绍了室内监控视频动态目标区域的形态特征信息和像素级特征信息的提取和融合，使得视频时序信息进行降维成为单一时间上下信息数据。目前，主流的时序信息深度学习分类算法有循环神经网络（Recurrent Neural Network, RNN）【59】、LSTM算法（中间通过引入穿插Bi-LSTM算法）和GRU算法。与卷积神经网络相比，循环神经网络通过增加神经元间权值的方式将当前神经元的输出直接循环传输至下一个时间点的输入信息，实现存储时序数据特征记忆的深度学习算法。短时序RNN在CNN的基础上仅添加一个权值W参数，使得特征输出信息由当前输入和短时历史输入特征共同学习的过程。RNN的网络单元结构如图【】
图【短时序循环神经网络单元结构图】
当前时间戳输入结果如公式（）
【公式（）】
其中表示
将上述单元结构按照时序移动组合则实现对时序特征信息的分类预测，图【】是时间序列数据下短时序循环神经网络的算法结构图。
图【短时序循环神经网络结构图】
其中 表示时间戳特征信息输入数据，u v分别表示每一个时间戳使用多层感知机的特征提取学习过程中的全连接层，o表示每个时间戳的输出数据。随着时序信息的多样化变迁，因短时序循环网络仅基于上一点时间戳获取时序关联性特征的学习方法导致在长时间序列上出现梯度消失的问题，【Sepp Hochreiter】等人【60】提出长短时记忆神经网络（LSTM），他们在RNN单元内增加了遗忘门、更新门和输出门以应对长时序信息特点，图【】展示LSTM神经网络单元的基本结构。
图【】
其中【】
分别对遗忘门、更新门和输出门进行介绍。基于以上对LSTM的分析，【】四个参数是LSTM的训练学习参数。【Carla】等人【61】提出一种结合两条LSTM网络结构的双向LSTM用于提取更多的时序数据相关性特征信息，他们将时序数据依照时间戳分别正向输入顺序LSTM网络和反向输入逆序LSTM以融合更多时序间上下文特征，其结构如图【】所示。【陈勇】等人【62】提出一种引入自注意力机制的Bi-LSTM跌倒检测算法，首先他们使用Mask R-CNN建立背景模型的方法提取视频动态目标特征信息，然后构建软注意力模型对每个时间间隔步长内的动态目标特征信息加权用于加深时间间隔内变化梯度大的特征值使得双向长短记忆神经网络可以有效检测跌倒行为。值得关注的是Bi-LSTM的权值参数只在单一网络结构中具有共享性而网络间具有独立性，因此Bi-LSTM的训练算力消耗和损失递归计算过程耗时更高。
【】等人提出引入门控制单元（,GRU）的循环序列神经网络结构，其只包含【】、【】，单元结构如图【】。
【图 GRU单元结构模型】
【结构分析】，根据上述结构分析，GRU仅需要训练【】【】个参数。
基于以上主流的时序信息处理深度学习算法，GRU引入门操作不仅可以解决RNN在长时间序列信息训练上梯度消失的问题，而且与LSTM网络相同具有一定的算法收敛性。同时，GRU隐藏了记忆长序列数据以节省资源消耗，网络结构相对简单且参数训练更少，属于轻量级深度循环神经网络，因此本文选择GRU作为视频时序信息类跌倒行为和跌倒行为分类训练算法。具体算法内部流程如下【搞一个伪代码或表】
【伪代码】
【流程解释】+ Dropout层简介和用途
【与卷积神经网络相比，循环神经网络增加网络细胞间权值连结学习时序相关信息】
GRU与LSTM算法类似都加入了门控操作来提取更多时序间相关性信息，都解决了RNN仅使用上下文序列信息更新当前特征导致的梯度消失问题。同时，从GRU单元结构可以看出。
【在真实情况下，跌倒视频数量比其他行为数据量少且跌倒过程持续时间短的特点，研究数据的限制容易造成跌倒检测算法的过拟合问题，因此本文在每个门控单元增加了Dropout层来减少网络算力消耗，解决过拟合问题】
在现实生活中，一个功能性和实用性较强的跌倒行为检测算法不仅要检测出视频中已经发生的跌倒行为，还要对跌倒行为进行预测。为了提升跌倒检测算法的应用性和功能效果，本文对双向LSTM算法进行轻量化模型改进。
时序数据特点，
对时序数据的算法介绍【循环神经网络】【LSTM】等介绍
【LSTM基本网络结构图】
【长短期记忆[25]是一种**递归神经网络（RNN）**，在深度学习和人类动作识别领域得到了越来越多的应用。与标准前馈神经网络不同，LSTM包括反馈连接。这种类型的递归神经网络不仅可以分析单个数据点（如照片），还可以分析整个数据序列（如语音或视频）。例如，LSTM可用于网络流量或入侵检测系统中的手写识别、语音识别和异常检测。典型的LSTM单元包括单元、输入端口、输出端口和忘记端口（如图5所示）。该单元存储无限长时间的值，三个门控制进出该单元的信息流。LSTM网络非常适合基于**时间序列数据**的分类、处理和预测，因为它们可以处理时间序列中重要事件之间的不确定延迟。LSTM是为了解决训练传统RNN时可能遇到的消失梯度问题而开发的。LSTM相对于标准RNN、隐马尔可夫模型和其他顺序学习方法的优势在于其在特定长度范围内的低灵敏度。理论上，RNN可以遵循输入序列中的任何长期关系。然而，RNN的问题是计算性质：当使用反向传播训练RNN时，反向传播梯度可能会降级（即趋于零）或“爆炸”到无穷大。由于LSTM单元允许梯度保持恒定，因此使用LSTM单元的RNN可以部分缓解梯度退化问题。然而，这些LSTM仍可能存在梯度“爆炸”问题。】
【LSTM(Long Short-Term Memory)
长短期记忆（LSTM）是一种递归神经网络，能够解决短期或长期依赖问题和消失的梯度问题。LSTM网络非常擅长对顺序数据进行建模，因为它使用一系列“门”来调节网络中的进出信息。为了开始LSTM网络训练，使用128个存储单元定义单个LSTM隐藏层，并将返回序列设置为True以输出每个时间步长的所有隐藏状态。随后是0.5个漏失层，以减少模型训练期间的过度拟合问题。然后，将学习到的特征展平为一个长向量，最终将其传递给一个完全连接的层
Gated Recurrent Unit(GRU) Model门控递归单元（GRU）模型
门控递归单元（GRU）是一种门控机制，其工作方式与LSTM类似，只是在GRU中删除了单元状态。GRU只有两个门：重置门和更新门。为了决定网络内的信息传递，使用了两个声明的门和隐藏状态。由于所使用的门和训练参数较少，GRU相对较不复杂，执行和训练速度比LSTM快。为了开始GRU网络训练，使用128个内存单元定义了一个GRU隐藏层，并将返回序列设置为True，以返回时间步骤中的最后一个输出。随后是0.5个漏失层，以减少模型训练期间的过度拟合问题。然后，将学习到的特征展平为一个长向量，最终将其传递给一个完全连接的】
轻量化改造网络结构
## 实验结果与分析
### 实验设置
目标检测 - YOLO+Pose 【14】
跌倒历史模板 - 【17】fall Module
阈值判断 - 骨骼形态特征+阈值 - 【46】Pose-trt
机器学习分类算法 - SVM/XGBoost - Pose+classifier 【48】
时空卷积神经网络 -  基于多算法融合的跌倒行为识别 【64】
融合注意力机制的双向长短期记忆递归神经网络方法 - Attention+Bi-LSTM 【62】
融合卷积神经网络的门控循环网络方法 - CNN+GRU 【65】

【代表目标检测的、跌倒历史模板判别方法、阈值判断方法、机器学习分类算法、长短期记忆递归神经网络方法、融合注意力机制的双向长短期记忆递归神经网络方法、融合卷积神经网络的门控循环网络方法】
使用的对比方法简介+引用
软硬件 表格
### 验证Transformer-EnGRU算法性能
【从两个方面验证本文算法，第一个方面验证本文算法分类效能是否提升，根据本文第二章节设计构建的训练样本数据集中选择不同运动场景下的室内监控场景验证本文算法分类准确性能；第二方面验证本文算法在复杂室内监控场景下跌倒检测的抗干扰能力和鲁棒性】
#### 不同算法对于跌倒行为检测性能分析 表
算法性能评价指标  TPR召回率 TNR特异性 精准性PPV 综合评价指标F1 帧率
YOLO+Pose[14] 14-16
Fall Module[19] 17-19
Pose-trt[46] 46-12
Pose+Classifer[48] 48-13
Pose+ST-GCN[64] 64-17
Attention+Bi-LSTM[62] 62-17 
CNN+GRU[65] 65-19
Transformer-EnGRU
#### 不同跌倒行为场景的算法鲁棒性分析 柱状图
环境干扰源图

不同视角
## 本章小结
本章节


