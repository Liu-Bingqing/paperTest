# 摘要 v5
## 中文摘要
老年群体意外摔倒是造成老年人受伤和死亡的主要原因之一，跌倒后及时报警和救治能够极大降低独居老人摔伤致死率。如何高效及时检测跌倒行为已经成为保障独居老年群体健康和生命安全的社会问题。传统穿戴式传感器容易丢失、携带不便，因此基于穿戴传感器的跌倒检测方法仅适用于实验医疗场景。依托网络信号的物联网家居异常行为检测方法设备造价较高且存在一定隐私泄露问题。随着家用监控设备的发展和普及，许多家庭安装室内监控摄像机对独居老人进行行为检测和安全监护工作，基于计算机视觉的跌倒行为检测方法对保障老年群体人身安全有重要意义。
为贴近真实独居老年人群的生活场景，本文针对室内单目监控视频数据分析研究跌倒行为检测方法，提出一种基于视频时间序列特征信息的跌倒检测方法。方法由监控视频动态目标提取算法、多特征提取方法和融合Transformer-EnGRU跌倒行为检测算法组成，能够检测出室内单目监控视频中动态目标的跌倒行为。本文主要工作如下：
（1）本文分析室内单目监控视频场景特点和视频动态目标跌倒行为过程，针对室内单目监控视频光照不均产生的运动阴影干扰和设备、环境因素产生的抖动问题，提出一种融合特征匹配和自适应阈值改进帧差算法的监控视频动态目标提取方法。该方法保留视频动态目标的时序特征信息和目标动态剪影区域，在一定程度上减少了室内监控视频常见干扰信息和背景冗余区域，能够有效提取室内监控视频动态目标。
（2）本文通过分析视频动态目标跌倒动作与其他行为差异，提取监控视频动态目标区域的最优拟合椭圆数据、重心速度变化数据和高度加速度变化数据作为动态目标形态特征信息，仅保留监控视频中动态目标时间上下文特征实现监控视频时空特征降维以简化算法输入数据。同时，本文使用卷积神经网络提取监控视频动态目标区域的像素级特征信息增强特征表征能力。
（3）本文使用多注意力机制Transformer算法实现视频动态目标多特征信息融合工作，进一步加强目标行为特征表征能力和时间序列关联性。本文引入损失函数正则化和Dropout层改进门控循环网络单元，在一定程度上减少了时序处理算法的训练过拟合问题和权重递归消减问题。
（4）本文基于主流软件开发模块框架设计开发了一款可连接本地监控设备的跌倒检测可视化界面，使用Python语言和可视化开发库封装Transformer-EnGRU室内单目监控视频跌倒检测算法并嵌入可视化界面计算层，直观展示图形界面的操作流程和跌倒行为检测结果。

## 英文摘要
Accidental falls is one of the main causes of injury and death in the elderly population. Timely alarm and treatment after falls can greatly reduce the mortality rate in the elderly living alone. How to detect falls efficiently and timely has become a social problem to ensure the health and life safety of the empty nest elderly. Traditional wearable sensors are easy to lose and inconvenient to carry, so the fall detection method based on wearable sensors is only suitable for experimental medical scenarios. The IoT home abnormal behavior detection method based on network signal has high equipment cost and certain privacy leakage problems. With the development and popularization of household monitoring equipment, many families install indoor surveillance cameras to conduct behavior detection and safety monitoring for the elderly living alone. The fall behavior detection method based on computer vision is of great significance to ensure the personal safety of the elderly.
In order to approach the real-life scenarios of elderly individuals living alone, this paper focuses on analyzing indoor monocular surveillance video data and researching fall behavior detection methods, and proposes a fall detection method based on video time series feature information.The method consists of dynamic target extraction algorithm, multi-feature extraction method and fusion Transformer-EnGRU fall behavior detection algorithm, which can detect the fall behavior of dynamic targets in indoor monocular surveillance video. The main work of this paper is as follows:
(1) This paper analyzes the characteristics of indoor monocular surveillance video scenes. Aiming at the problem of moving shadow interference caused by uneven illumination of indoor monocular surveillance video and the jitter caused by equipment and environmental factors, this paper proposes a dynamic object extraction method for surveillance videos that integrates feature matching and adaptive threshold improvement frame difference algorithm. The method reduces the common interference information and background redundancy area of indoor surveillance video to a certain extent, and effectively extracts the dynamic target area and temporal feature information of video.
(2) This paper analyzes the difference between the fall action process of the video dynamic target and other behaviors, and extracts the optimal fitting ellipse data, the center of gravity velocity change data and the height acceleration change data of the dynamic target area of the surveillance video as the morphological feature information of the dynamic target.In order to reduce the dimension of the spatio-temporal features of the survillance video and simplify th algorithm input data structure, the paper only retain th dynamic target time context features in the surveillance video. Meanwhile, this paper uses convolutional neural network to extract pixel-level feature information of dynamic target area of surveillance video to enhance feature representation ability.
(3) In this paper, the multi-attention mechanism Transformer algorithm is used to realize the multi-feature information fusion of video dynamic targets, further enhancing the target behavior feature representation ability and time series correlation. This paper uses the loss function regularization and Dropout layers are introduced to improve the gated loop network unit, which reduces the training overfitting problem and the weight recursive reduction problem of the time series processing algorithm to a certain extent.
(4) Based on the mainstream software development module framework, this paper designs and develops a visual interface for fall detection that can be connected to local monitoring equipment. The Python language and visual development library are used to 
encapsulate the Transformer-EnGRU indoor monocular surveillance video fall detection algorithm and embed the visual interface calculation layer, visually display the graphical interface operation process and fall behavior detection results.



# 关键词
## 中文关键词
目标检测 跌倒检测 门控循环单元 Transformer
## 英文关键词
Object Detection Fall Detection GRU Transformer

## v8 终稿版
### 中文摘要
意外摔倒是造成老年群体受伤和死亡的主要原因之一，跌倒后及时报警和救治能够极大降低独居老人摔伤致死率。如何高效及时地检测跌倒行为已成为保障独居老年群体健康和生命安全的社会问题。传统穿戴式传感器容易丢失且携带不便，仅适用于实验医疗场景下跌倒检测的研究。依托于网络信号的物联网家居设备造价相对较高，在异常跌倒行为检测过程中存在一定的隐私泄露问题。随着家用监控设备的发展和普及，许多家庭安装室内监控摄像机对独居老人进行行为检测和安全监护，研究基于计算机视觉的跌倒行为检测方法对保障老年群体人身安全有重要意义。

本文针对独居老人的生活场景，分析研究室内单目监控视频数据下动态目标跌倒行为的特点，提出一种基于处理视频时序特征信息的跌倒检测方法。该方法由监控视频动态目标提取算法、多特征提取方法和融合Transformer-EnGRU跌倒行为检测算法组成，能够检测出室内单目监控视频中动态目标的跌倒行为。本文主要工作如下：

(1) 本文通过分析室内单目监控视频场景，针对图像数据中光照不均产生的运动阴影干扰和设备、环境因素产生的抖动问题，提出一种融合特征匹配和自适应阈值的改进帧差监控视频动态目标提取算法。实验结果表明，该方法在一定程度上减少了室内监控视频常见的干扰信息和背景冗余区域，可有效提取视频动态目标区域和时序特征信息。

(2) 本文通过分析视频动态目标的跌倒动作与其他行为的特征差异，提取监控视频动态目标区域的最优拟合椭圆数据、重心速度变化数据和高度加速度变化数据作为动态目标形态特征信息。仅保留监控视频中动态目标时间上下文特征，简化算法输入数据维度。同时，使用卷积神经网络提取监控视频动态目标区域的像素级特征信息，以增强特征表征能力。

(3) 为进一步加强目标行为特征表征能力和视频时序信息关联性，本文使用多注意力机制Transformer算法融合视频动态目标的形态和像素级多特征信息。同时，引入损失函数正则化和Dropout层改进门控循环网络单元进行跌倒行为检测。实验结果表明，本文提出的Transformer-EnGRU算法在一定程度上降低了训练过拟合，跌倒检查性能相较于其他算法有一定提升。

(4) 基于主流的软件开发框架，本文设计开发了一个可连接本地监控设备的跌倒检测可视化界面。使用Python语言和可视化开发库封装Transformer-EnGRU室内单目监控视频跌倒检测算法并嵌入至可视化界面的计算层，直观展示图形界面的操作流程和跌倒行为检测结果。



### 英文摘要
Accidental fall is one of the main causes of injury and death in the elderly. Timely alarm and treatment after fall can greatly reduce the mortality rate of falls among elderly living alone. How to detect fall behavior efficiently and timely has become a social problem to ensure the health and safety of the empty nest elderly. Traditional wearable sensors are easy to lose and inconvenient to carry, and are only suitable for fall detection in experimental medical scenarios. The cost of IoT home devices relying on network signals is relatively high, and there is a certain privacy leakage problem in the process of abnormal fall behavior detection. With the development and popularization of household monitoring equipment, many families install indoor surveillance cameras to conduct behavior detection and safety monitoring for elderly people living alone. It is of great significance to study the fall behavior detection method based on computer vision to ensure the personal safety of the elderly.

Aiming at the living scene of the elderly living alone, this paper analyzes and studies the characteristics of dynamic target fall behavior under indoor monocular surveillance video data, and proposes a fall detection method based on processing video timing feature information. This method consists of dynamic target extraction algorithm, multi-feature extraction method and fusion Transformer-EnGRU fall behavior detection algorithm, which can detect the fall behavior of dynamic targets in indoor monocular surveillance video. The main work of this paper is as follows :

(1) To solve the problem of moving shadow interference caused by uneven illumination in image data and jitter caused by equipment and environmental factors, this paper analyze the indoor monocular surveillance video scene, and propose an improved frame difference surveillance video dynamic target extraction algorithm that integrates feature matching and adaptive threshold. The experimental results show that this method reduces the common interference information and background redundant areas of indoor surveillance video to a certain extent, and can effectively extract the dynamic target area and temporal feature information of video.

(2) In this paper, by analyzing the characteristics of the fall action of the video dynamic target and other behaviors, the optimal fitting ellipse data, the optimal fitting ellipse data, the center of gravity velocity change data and the height acceleration change data of the dynamic target area of the surveillance video are extracted as the dynamic target morphological feature information. Only the dynamic target time context features in the surveillance video are retained, and the algorithm input data dimension is simplified. In addition, the convolutional neural network is used to extract the pixel-level feature information of the dynamic target area of the surveillance video to enhance the feature representation ability.

(3) To further strengthen the representation ability of target behavior features and the correlation of video timing information, this paper uses the multi-attention mechanism Transformer algorithm to fuse the morphological and pixel-level multi-feature information of video dynamic targets. In addition, the loss function regularization and the Dropout layer are introduced to improve the gated recurrent network unit for fall behavior detection. The experimental results show that the Transformer-EnGRU algorithm proposed in this paper reduces the training overfitting to a certain extent, and the fall detection performance is improved compared with other algorithms.

(4) Based on the mainstream software development framework, this paper designs and develops a visual interface for fall detection that can be connected to local monitoring devices. The Python language and visual development library are used to encapsulate the Transformer-EnGRU indoor monocular surveillance video fall detection algorithm and embed it into the calculation layer of the visual interface, visually display the operation flow and fall behavior detection results of the graphical interface.
