# 第二章- 二 室内单目监控视频场景跌倒检测分析与设计（室内单目监控视频场景定义）
## 2.1 人体行为活动分类【可以放在特征提取中】
随着人们社会和科技的发展，人们的日常生活活动变得越来越复杂，人体行为类别变得更多样化。人体行为检测是医疗领域和监控安全领域中重要的研究方向之一。跌倒行为活动是人体行为活动中占比较少，但其过程的复杂度和重要性是人体行为研究的热点领域和重要环节，是人体活动研究领域具有重要医学研究价值和保障人身安全的研究方向之一。因此，从人体行为活动的基础上分析研究跌倒行为的发生和过程具有理论价值和意义。【Ahmed】[16 Human Activity Classification Based on Angle Variance Analysis Utilizing the Poincare Plot 2021]等人使用嵌入式三轴加速度计智能手机收集人体目标重力分量和加速度矢量作为分析人体行为活动的特征样本，根据庞加莱图性质的长短期变化分析身体活动强度对人体行为活动进行分类研究。他们将人体行为活动分为静态和动态两大类，依据身体加速度分量和重力分类平均角度将静态人体活动划分为躺状态、站状态和站立状态，通过庞加莱图特性角度将动态人体活动划分为走状态和跑状态。
根据上述对人体日常行为活动研究，本文对室内场景下老年人跌倒行为的发生原因、活动过程和活动后续人体行为特征进行研究和分析，跌倒行为前期一般是站立、慢走、坐下和蹲下等动态人体活动行为，因身体机能瞬间下降或绊倒阻力因素发展为突发性躯干倾斜和运动加速度瞬间增加导致失衡状态，后续则出现因撞击冲击力导致人体目标形变，针对老年人群一般出现人体行为模式变为躺姿势的静态行为状态，因此人体跌倒行为过程是首先是正常动态活动过程，再到突发坠落失衡过程，最终到静态活动过程，研究分析跌倒行为坠落开始倾向因素和开始失衡特征信息是基于计算机视觉的跌倒行为检测的难点和重点之一。
## 2.2 场景定义与跌倒行为分析
### 2.2.1 室内单目监控视频场景定义
理想状态下实验室场景被称为简单场景，其特点是背景基本无明显变化、实验环境较稳定且无光影和动态背景干扰、人物目标行为单一。在简单场景下的目标提取和跌倒识别精准度一般较高，但简单场景规避掉许多现实场景中的无法避免的现象，例如室内光影变化导致动态阴影干扰，设备噪声以及家庭家居遮挡人体目标问题等。近几年，许多研究人员对复杂场景视频进行更深入的分析研究以提升模型在实际应用性。【Si】[17 Research on Video-Based Human Action Behavior Recognition Algorithms 2020]等人提出一种基于背景减法的动态目标提取并进行阈值分类的室内监控视频跌倒行为检测的方式，该方法研究场景和数据基于自建数据，其特点是固定目标受试者在相同时间限制下完成固定动作的过程，并且背景单一稳定无明显光影变化干扰和其他噪声影响。根据以上分析可以看出基于室内监控视频的简单实验场景的定义是：目标动态背景稳定无干扰，实验环境单一，实验受试者单一且完成轨迹要求动作。许多医学研究中使用实验室场景进行跌倒行为细致化分析研究，但该场景情况规避许多复杂场景中的现实因素。【朱泽宇】[18 基于复杂场景的跌倒行为检测研究 2020]等人提出一种基于YOLOv5和卷积神经网络的跌倒行为检测方法，该方法建立在复杂场景数据的研究基础上对视频数据进行预处理操作，包括光照变化鬼影判别及降噪处理等，他们构建复杂场景数据集合以实现不同场景下的跌倒行为检测本文的研究场景是室内单目监控视频，室内研究场景受到光照变化、抖动噪声和非人体运动目标的影响，属于复杂场景中的一类研究对象。人体行为检测视频数据分为RGB数据、RGB-D数据及多视角视频数据。【徐壮】[19 室内监控环境下的跌倒行为检测算法研究 2021]等人提出一种基于RGB-D视频的时序特征分类跌倒行为检测方法，他们介绍RGB-D图像是利用嵌入监控设备摄像机的两个红外传感器和一个红外点阵投射器捕获室内环境中的深度图像，因此在视频预处理阶段不仅需要对RGB三通道图像进行处理，还需要对深度数据进行处理滤波。RGB-D数据在三通道图像数据基础上增加深度通道，为跌倒检测模型提供更多的特征信息但增加模型的耗时和算力执行要求。【Slembrouck】[20 Multiview 3D Markerless Human Pose Estimation from OpenPose Skeletons]等人使用多监控设备重建聚类关键点方式实现多视角构建构建三维人体模型进行跌倒行为比对检测方法，该方法在跌倒行为特征信息提取方面需要大量处理消耗，并且在居家监控中一般不适用多视角监控单一目标。本文根据模型实际应用角度和家用监控设备普遍性特点，仅使用单目RGB三通道室内监控视频数据信息实现基于计算机视觉的跌倒行为检测。
基于以上场景分析，本文研究对象满足以下要求：
1. 室内环境：存在家居或其他设施模拟居家环境中家居遮挡情况。
2. 单目监控设备：通过未嵌入传感器监控设备记录研究数据，基于计算机视觉特征提取方法进行目标行为检测研究。
3. 存在多动态目标：数据中需要包含人体目标区域和非人体目标动态区域，且模拟实际场景下干扰源信息。
4. 存在多人体行为活动：数据中包含多种人体行为模式，根据不同行为模式跌倒情况提取特征信息。
## 2.3 场景数据集设计 【后续进行补充】
根据场景分析和定义，本文根据跌倒检测模型的需求和研究内容收集研究数据集并设计实验样本数据以提升动态目标检测的灵活性，以及提升老年人跌倒行为特征提取和检测的准确性和鲁棒性。
### 2.3.1 实验数据集
根据本文研究场景定义和需求，收集分析基于室内单目监控视频场景下的不同拍摄视角、不同室内环境设施构造和不同目标对象的数据集作为本文跌倒行为检测数据样本，并且视频包含人体多种运动活动和非人体运动目标作为参照样本进行算法性能对比实验。本文使用以下数据集作为研究数据：
1. URFD数据集 （UR Fall Detection Dataset）
URFD数据集(UR Fall Detection Dataset)[21 ]由【Kepski】等人于2015年使用两台Microsoft Kinect相机分别记录跌倒序列的RGB数据和深度数据。该数据是由30组人体跌倒行为和40组人体正常活动行为的RGB视频序列组成，视频分辨率为640×480px。本文分析该数据中跌倒视频包含直立型跌倒和坐蹲式跌倒情况，正常活动行为序列中包含光照变化干扰和许多类跌倒行为，符合本文对跌倒行为判断研究划分。跌倒行为占完整视频比重大有利于对跌倒行为进行特征提取与分析。
【21 Kepski M, Kwolek B (2015) Embedded system for fall detection using body-worn accelerometer and depth sensor. In: 2015 IEEE 8th International conference on intelligent data acquisition and advanced computing systems: technology and applications (IDAACS), vol 2, pp 755–759. IEEE】
2. UCF101数据集
UCF101数据集[22 ]由【Soomro】等人于2010年收集自YouTube的人体动作视频数据，该数据总共包含101个动作类别的13320个视频序列，分辨率为240×320像素。该视频数据主要包括人与物体交互活动、单一肢体动作、人与人之间互动活动、弹奏乐器和体育运动等，例如涂口红、射箭、足球等。本文选择该数据集中的类跌倒行为蹲下和老年人运动太极视频作为研究数据，共130个视频序列。本文主要分析蹲下和太极动态运动的特征与跌倒行为活动的差异，验证动态目标检测模型的鲁棒性并提升跌倒行为检测模型的精确性。
【22 UCF101 A Dataset of 101 Human Actions】
3. Weizmann 数据集
Weizmann数据集[23 ]由【Gorelick】等人于2005年使用固定视角拍摄的10种动态人体目标视频，该数据集由90组常规运动数据和21组用于检测算法鲁棒性的动态视频数据，分辨率为180×144px。数据中使用遮挡物模拟室内场景中家居对动态目标遮挡情况，以及其他类跌倒行为活动。本文选择该数据集中走路、弯腰和遮挡数据作为跌倒行为检测模型的研究数据集。
【23 Actions as Space-Time Shapes - weizmann dataset cite01】
4. KTH 数据集
KTH数据集[24 ]由【Schuldt】等人于2004年使用固定单目镜头拍摄的6种人体动作视频序列，包含步行、慢跑、拳击、挥手和拍手动作，分辨率为160×120px。该数据集一共总共2391个视频序列，每个动作由25个人物分别在室外和室内不同场景下采集视频数据，每个视频平均时长4秒。本文选择其中的步行和慢跑动作作为模拟老年人群里的动态行为数据，用于验证基于监控视频的动态目标检测模型。
【24 Recognizing_human_actions_a_local_SVM_approach】
5. MCF 数据集
MCF(Multiple Cameras Fall)数据集[25 ]由【Auvinet】等人于2010年使用8个摄像机拍摄不同视角的跌倒行为视频，分辨率为720×480px。该数据集每个视角都是单目RGB视频序列数据，包含24个不同场景，其中前22个场景包含跌倒行为和正常行为活动，最后两个场景为混合行为活动视频。本文选择该数据集中不同视角数据几乎覆盖家用监控设备不同安装位置下人体行为活动特点，本文选择该数据集作为样本数据验证基于室内监控视频跌倒行为检测模型的鲁棒性和准确性。
【25 E. Auvinet, C. Rougier, J.Meunier, A. St-Arnaud, J. Rousseau, "Multiple cameras fall dataset", Technical report 1350, DIRO - Université de Montréal, July 2010.】
### 2.3.2 实验数据样本设计
本文基于老年群体身体形态特点选择URFD数据集中6组跌倒视频共832帧图像作为分析研究跌倒行为特点的基准数据集，同时选择URFD数据中15组的ADL动态目标运动数据集和UCF数据集中5组老年人常见运动视频数据作为非跌倒行为动态目标检测基准数据集。本文基准数据集中涵盖老年入日常行为中常见活动，例如走、慢跑和运动等正常动态姿势，这些数据中存在部分目标遮挡情况和光照强变化情况以用于提升动态目标提取的准确性和鲁棒性。同时，基准数据集中有蹲下、坐下和躺下等类跌倒行为，用于分析研究跌倒行为特征信息的提取以降低跌倒行为检测和预判的误判率。
为了验证本文前景目标提取模型和跌倒行为检测模型的真实判断能力，本文基于上述介绍的数据集对跌倒检测模型样本数据进行重构如表{模型训练样本数据集设计}。
【设计】【增加部分用于训练的样本数据集数据图片】
模型训练样本的设计不仅涵盖老年人日常正常行为活动和跌倒行为活动，而且考虑监控设备分辨率的差异性进行不同数据集的融合构建。同时，根据室内场景的特点选择光照变化较大、遮挡目标和单目监控设备不同安装视角的人体目标动态监控视频数据集，基本还原现实场景监控视频出现的跌倒检测模型面临的动态行为和问题。从样本设计可以看出本文跌倒检测算法识别的三种判断预期效果：1. 算法对正常人体行为不进行训练以节约算力和时间资源。2. 对类跌倒行为活动进行行为检测，经过特征提取后判断是否含有跌倒趋势以进行预测，如果无明显跌倒趋势特征则检测为安全姿态，否则进行检测并提示。3. 算法对跌倒行为进行检测并提示。因此，从人体活动行为分析和样本设计中可以将跌倒行为检测复杂问题简化为简单的分类问题。
## 2.4 模型性能评估指标
根据模型训练样本设计可以看出，基于室内单目监控视频的老年人跌倒检测问题实际是类跌倒行为样本和跌倒行为样本的二分类问题，评估分类模型常用的性能评价指标有ACC(Accuracy 准确性)、PPV(Positive Predictive Value 精准性)、TPR(True Positive Rate 召回率)、TNR(True Negative Rate 特异性)和F1(F1 Score F1指标1)【26】。准确性和F1指标可以评估模型整体性能，准确性表示模型分类结果中正确分类样本占总体样本的比值，F1指标是精准性和召回率的综合指标，F1指标值趋近于0说明模型整体性能较差，趋近于1则模型整体性能较好，兼顾精准性和召回率。精准性表示模型检测是跌倒结果中真正跌倒行为样本与全部分类为跌倒结果样本的比值。召回率表示检测是跌倒结果中真正跌倒行为样本与全部标签是跌倒行为样本的比值，该指标用于评估模型正确识别跌倒行为。特异性表示在模型检测结果是类跌倒行为中真正类跌倒行为的占比，该指标用于评估模型正确识别类跌倒行为。本文研究的最终目的是对室内监控视频动态目标跌倒行为的判断和预估，因此需要建立对模型是否能准确判断动态目标跌倒行为的评价指标。同时，检测过程的总体耗时和检测速率是验证跌倒行为检测模型实时性的重要评估指标之一。因此，本文选择TPR、TNR和F1作为本文跌倒检测模型的评估指标，并且使用FPS(Frame per Second 帧率)计算模型在样本视频中每秒处理的帧数，用于评估模型的实时性。公式如下：
【评估指标公式 要把PPV、TPR、TNR、F1、FPS都列出】
fps = frameNum / elapsedTime;
其中，本文基于计算机视觉的跌倒行为检测在模型样本分类时的结果如下：
1. TP(True Positive 真正例)表示基于样本类别是跌倒行为的样本，即sitFall和standFall标签的样本，模型检测结果类别仍是跌倒行为的样本数量
2. TN(True Negative 真反例)表示基于样本类别是跌倒行为的样本，而模型检测结果类别是类跌倒行为的样本数量。
3. FN(False Negative 假反例)表示基于样本类别是类跌倒行为的样本，即squat、sitDown和lieDown标签的样本，模型检测结果类别是类跌倒行为的样本数量。
4. FP(False Positive 假正例)表示基于样本类别是类跌倒行为的样本，而模型检测结果类别是跌倒行为的样本数量。

【26 Fall Detection Based on RetinaNet and MobileNet Convolutional Neural Networks-二分类CNN - 2020】

【平均精度（mAP）。单类别平均精确率（AP）是P-R曲线与坐标轴之间的面积】

## 2.5 本章小结
本文介绍了人体行为识别和跌倒行为判断的基本理论基础，基于人体行为活动类别对跌倒行为活动进行分析，并分析基于计算机视觉的跌倒行为检测存在的问题和难点，阐述研究场景室内单目监控视频场景的定义以及基于该场景老年人日常行为活动和跌倒行为活动的特点，简述研究分析数据集，并根据室内单目监控视频中跌倒行为检测需求分析设计视频动态前景目标提取和跌倒行为检测模型训练样本数据集来提升模型检测性能，最后介绍评估本文研究模型的性能评估指标。
