# 目录
## v0.0.0.0 - v0.0.0.1
摘要
ABSTRACT
第一章　绪论	1
1.1　研究背景及意义	1
1.2　国内外研究现状	2
1.2.1　基于传感器的跌倒检测技术	2
1.2.2　基于物联网的跌倒检测技术	3
1.2.3　基于计算机视觉的跌倒检测技术	5
1.3　研究内容及主要创新点	6
1.3.1　本文主要研究内容	6
1.3.2　创新点与贡献	7
1.4　论文组织结构安排	8
1.5　本章小结	8
第二章　人体行为检测理论基础和场景定义	9
2.1　人体行为检测理论基础	9
2.2　场景定义	11
2.3　实验数据集设计	11
2.3.1　研究数据集	11
2.3.2　实验数据样本设计	13
2.4　算法评估指标	16
2.5　本章小结	19
第三章　融合特征匹配改进帧差法动态目标提取算法	20
3.1　监控视频动态目标提取主流算法	20
3.1.1　帧差法	21
3.2.1　光流法	21
3.3.1　背景减法	21
3.4.1　视频动态目标提取算法对比	21
3.2　视频动态目标提取面临问题与挑战	21
3.3　融合特征匹配与自适应阈值改进帧差法算法设计	24
3.3.1　算法结构整体设计	24
3.3.2　数据预处理	25
3.3.3　HFID算法构建过程	25
3.4　实验结果与分析	28
3.5　本章小结	31
第四章　融合Transformer-EnGRU跌倒检测算法	32
4.1　基于计算机视觉的跌倒检测主流方法	32
4.1.1　阈值分析法	35
4.1.2　机器学习方法	35
4.1.3　深度学习方法	35
4.1.4　主流跌倒检测方法对比	35
4.2　跌倒检测面临问题与挑战	32
4.3　跌倒行为特征信息分析与提取	32
4.3.1　视频动态目标形态特征信息分析提取	35
4.3.2　基于卷积神经网络的动态目标像素级特征提取	35
4.4　融合Transformer多特征门控循环网络的跌倒检测算法	35
4.4.1　Transformer-EnGRU算法整体设计	35
4.4.2　引入Transformer的动态目标多特征融合	37
4.4.3　引入Dropout层的改进GRU得到检测分类算法	38
4.5　实验结果与分析	42
4.5.1  实验设置	38
4.5.2  Transformer-EnGRU算法性能验证	38
4.6　本章小结	42
第五章　总结与展望	64
5.1　工作总结	64
5.2　未来展望	65
参考文献	66
在读期间公开发表的论文和承担科研项目及取得成果一览	71
致谢	72
## v0.0.0.2 - v0.0.0.5 v1 v2 v3
摘要
ABSTRACT
第一章　绪论	1
1.1　研究背景及意义	1
1.2　国内外研究现状	2
1.2.1　基于传感器的跌倒检测技术	2
1.2.2　基于物联网的跌倒检测技术	3
1.2.3　基于计算机视觉的跌倒检测技术	4
1.3　研究内容及主要创新点	7
1.3.1　本文主要研究内容	7
1.3.2　创新点与贡献	7
1.4　论文组织结构安排	8
1.5　本章小结
第二章 研究场景定义及相关技术
2.1 目标检测相关技术
2.1.1 帧差法
2.1.2 光流法
2.1.3 背景减法
2.2 视频时序信息处理相关技术
2.2.1 循环神经网络
2.2.2 长短期记忆网络
2.2.3 门控循环网络单元
2.3 场景定义
2.4　实验数据集设计	11 - 单独放在每个章节实验设计
2.5　评估指标	16 - 仅放公式 具体解释放在每章节实验
2.6　本章小结	19
第三章 融合特征匹配改进帧差动态目标提取方法
3.1 问题描述
3.2 融合特征匹配与自适应阈值改进帧差算法
3.2.1 整体设计
3.2.2 数据预处理
3.2.3 HFID算法构建过程
3.3 实验结果与分析
3.3.1 实验设置 - 实验指标具体说明及实验涉及相关数据集说明
3.3.2 实验结果分析
3.4 本章小结
第四章 融合多注意力机制Transformer改进GRU跌倒检测方法
4.1 问题描述
4.2 动态目标特征信息分析与提取 - 加入人体行为检测理论基础（或放在第四章 跌倒行为特征提取）
4.2.1 动态目标形态特征信息分析与提取
4.2.2 基于卷积神经网络的动态目标像素级特征信息提取
4.3 融合Transformer-EnGRU跌倒检测算法
4.3.1 整体设计
4.3.2 基于Transformer的多特征融合算法
4.3.3 引入Dropout的改进GRU跌倒检测算法
4.4 实验结果与分析
4.4.1 实验设置 - 实验软硬件要求，实验指标具体说明及涉及数据集和方法说明
4.4.2 实验结果分析
4.5 本章小结
第五章 跌倒检测可视化设计
5.1 可视化结构设计
5.1.1 架构层次设计
5.1.2 开发结构设计
5.2 界面功能及操作
5.2.1 功能介绍
5.2.2 界面操作流程
5.3 可视化开发结果
5.3.1 主界面
5.3.2 监控设备连结界面
5.3.3 动作捕获界面
5.3.4 跌倒提示界面
5.4 本章小结
第六章 总结与展望
6.1 工作总结
6.2 未来展望
参考文献
在读期间科研成果
致谢

## v1 v2 v3
摘要
ABSTRACT
第一章　绪论	1
1.1　研究背景及意义	1
1.2　国内外研究现状	2
1.2.1　基于传感器的跌倒检测研究现状	2
1.2.2　基于物联网的跌倒检测研究现状	4
1.2.3　基于计算机视觉的跌倒检测研究现状	4
1.3　研究内容及主要创新点	7
1.3.1　本文主要研究内容	7
1.3.2　创新点与贡献	7
1.4　论文组织结构安排	8
第二章 理论基础和相关技术 9
2.1 视频动态目标提取相关技术 9
2.1.1 帧差法 9
2.1.2 光流法 10
2.1.3 背景减法 12
2.2 视频时序信息处理相关技术 13
2.2.1 循环神经网络 13
2.2.2 长短期记忆网络 14
2.2.3 门控循环网络单元 16
2.3 场景定义 17
2.4　实验数据集设计 18
2.5　评估指标 19
2.6　本章小结 19
第三章 融合特征匹配改进帧差动态目标提取方法 20
3.1 问题描述 20
3.2 融合特征匹配与自适应阈值改进帧差算法 21
3.2.1 整体设计 21
3.2.2 数据预处理 22
3.2.3 HFID算法构建过程 23
3.3 实验结果与分析 26
3.3.1 实验设置 - 实验指标具体说明及实验涉及相关数据集说明 26
3.3.2 实验结果分析 26
3.4 本章小结 30
第四章 融合Transformer-EnGRU跌倒检测方法 31
4.1 问题描述 31
4.2 动态目标特征信息分析与提取 - 加入人体行为检测理论基础（或放在第四章 跌倒行为特征提取） 32
4.2.1 动态目标形态特征信息分析与提取  33
4.2.2 基于卷积神经网络的动态目标像素级特征信息提取 39
4.3 融合Transformer-EnGRU跌倒检测算法 40 
4.3.1 整体设计 40
4.3.2 基于Transformer的多特征融合算法 40
4.3.3 引入Dropout的改进GRU跌倒检测算法 43
4.4 实验结果与分析 45
4.4.1 实验设置 - 实验软硬件要求，实验指标具体说明及涉及数据集和方法说明 45
4.4.2 实验结果分析 45
4.5 本章小结 48
第五章 跌倒检测可视化设计 49
5.1 可视化结构设计 49
5.1.1 架构层次设计 49
5.1.2 开发结构设计 50
5.2 界面功能及操作 53
5.2.1 功能介绍 53
5.2.2 界面操作流程 54
5.3 可视化开发结果 54
5.3.1 主界面 54
5.3.2 监控设备连结界面 55
5.3.3 动作捕获界面 56
5.3.4 跌倒提示界面 56
5.4 本章小结 57
第六章 总结与展望 58
6.1 工作总结 58
6.2 未来展望 59
参考文献 60
在读期间科研成果 65
致谢 66